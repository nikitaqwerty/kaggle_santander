{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.nn.modules.loss import BCEWithLogitsLoss, BCELoss\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df.target\n",
    "train = train_df.drop(['ID_code','target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filtered = pd.read_pickle('test_filtred.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filtered = test_filtered.loc[:,train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['ID_code'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train,test_filtered]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab8483e4c144bf7a9b10b96f5f5c677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vcs_train_test = {}\n",
    "\n",
    "\n",
    "for col in tqdm(train.columns):\n",
    "\n",
    "    vcs_train_test[col] = train_test.loc[:,col].value_counts()/300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c830b940414444b906fe6d1e29d2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(train.columns):\n",
    "\n",
    "    vtraintest = vcs_train_test[col]\n",
    "    \n",
    "    t = vtraintest[train[col]].fillna(0).values\n",
    "    train[col+'_train_test_sum_vcs'] = t\n",
    "    \n",
    "    train[col+'_train_test_sum_vcs_product'] = train[col]*t\n",
    "\n",
    "    t = vtraintest[test[col]].fillna(0).values\n",
    "    test[col+'_train_test_sum_vcs'] = t\n",
    "    \n",
    "    test[col+'_train_test_sum_vcs_product'] = test[col]*t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(pd.DataFrame(scaler.fit_transform(train),columns=cols),label ,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(scaler.transform(test),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e8284614f748b39fe7af919403895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_tensors = []\n",
    "val_tensors = []\n",
    "test_tensors = []\n",
    "\n",
    "for fff in tqdm(range(200)):\n",
    "    train_t = X_train[[f'var_{fff}',f'var_{fff}_train_test_sum_vcs',f'var_{fff}_train_test_sum_vcs_product']].values\n",
    "    val_t = X_val[[f'var_{fff}',f'var_{fff}_train_test_sum_vcs',f'var_{fff}_train_test_sum_vcs_product']].values\n",
    "    test_t =  test[[f'var_{fff}',f'var_{fff}_train_test_sum_vcs',f'var_{fff}_train_test_sum_vcs_product']].values\n",
    "    train_tensors.append(torch.tensor(train_t, requires_grad=False, device=device, dtype=torch.float32))\n",
    "    val_tensors.append(torch.tensor(val_t, requires_grad=False, device=device, dtype=torch.float32))\n",
    "\n",
    "    test_tensors.append(torch.tensor(test_t, requires_grad=False, device=device, dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1065, -0.9163, -0.8206], device='cuda:3')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tensors[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = torch.cat(train_tensors,1).view((-1,200,3))\n",
    "val_tensors = torch.cat(val_tensors,1).view((-1,200,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensors = torch.cat(test_tensors,1).view((-1,200,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1065, -0.9163, -0.8206], device='cuda:3')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tensors[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t = torch.tensor(y_train.values, requires_grad=False, device=device, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val.values, requires_grad=False, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = NN().to(device)\n",
    "# nn(val_tensors)\n",
    "\n",
    "# class customDataset(Dataset):\n",
    "#     def __init__(self, features, label):\n",
    "#         self.features = features\n",
    "#         self.label = label\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.label)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         features = [fs[idx] for fs in self.features]\n",
    "#         label = self.label[idx]\n",
    "#         sample = {'features': features, 'label': label}\n",
    "#         return sample\n",
    "\n",
    "# dataset = customDataset(train_tensors,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    random_seed = 42\n",
    "\n",
    "\n",
    "    def __init__(self, D_in=3, features = 200):\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        \n",
    "        super(NN, self).__init__()\n",
    "        self.layer = []\n",
    "        layer_size = D_in\n",
    "        enc_out = 30\n",
    "        for i in range(features):\n",
    "            \n",
    "            layer = torch.nn.Sequential(torch.nn.Linear(layer_size, enc_out//2),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(enc_out//2, enc_out),\n",
    "                                       torch.nn.ReLU())\n",
    "            setattr(self, 'layer_' + str(i), layer)\n",
    "        \n",
    "\n",
    "        self.linear3 = torch.nn.Linear(features*enc_out,1)        \n",
    "\n",
    "    def forward(self, y):\n",
    "        res = []\n",
    "        for i in range(200):\n",
    "            layer = getattr(self, 'layer_' + str(i))\n",
    "            res.append(layer(y[:,i,:]) )\n",
    "        y = torch.cat(res,1)\n",
    "        y = self.linear3(y)\n",
    "        return y\n",
    "    \n",
    "\n",
    "dataset = TensorDataset(train_tensors,y_train_t)\n",
    "nn = NN().to(device)\n",
    "loss_f = BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = Adam(params=nn.parameters(), lr = 0.005)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[15, 25, 35, 55], gamma=0.5)\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fcf4e11d6149cc98b851d66bc99adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "LOSS:  0.21647617\n",
      "AUC:  0.8856475014774677\n",
      "==================================================\n",
      "EPOCH 1\n",
      "LOSS:  0.20513403\n",
      "AUC:  0.8993997134809668\n",
      "==================================================\n",
      "EPOCH 2\n",
      "LOSS:  0.19711518\n",
      "AUC:  0.9065939039186015\n",
      "==================================================\n",
      "EPOCH 3\n",
      "LOSS:  0.19447933\n",
      "AUC:  0.9097528066140789\n",
      "==================================================\n",
      "EPOCH 4\n",
      "LOSS:  0.20154816\n",
      "AUC:  0.9119029978471473\n",
      "==================================================\n",
      "EPOCH 5\n",
      "LOSS:  0.1915914\n",
      "AUC:  0.9128838020971145\n",
      "==================================================\n",
      "EPOCH 6\n",
      "LOSS:  0.19141826\n",
      "AUC:  0.9136082814901059\n",
      "==================================================\n",
      "EPOCH 7\n",
      "LOSS:  0.19238143\n",
      "AUC:  0.915361619245401\n",
      "==================================================\n",
      "EPOCH 8\n",
      "LOSS:  0.1924795\n",
      "AUC:  0.9154098161230144\n",
      "==================================================\n",
      "EPOCH 9\n",
      "LOSS:  0.18816702\n",
      "AUC:  0.9162106205523219\n",
      "==================================================\n",
      "EPOCH 10\n",
      "LOSS:  0.19196324\n",
      "AUC:  0.916917050335318\n",
      "==================================================\n",
      "EPOCH 11\n",
      "LOSS:  0.18764824\n",
      "AUC:  0.9172302365625395\n",
      "==================================================\n",
      "EPOCH 12\n",
      "LOSS:  0.185636\n",
      "AUC:  0.9171841981599446\n",
      "==================================================\n",
      "EPOCH 13\n",
      "LOSS:  0.1894116\n",
      "AUC:  0.9168675413768274\n",
      "==================================================\n",
      "EPOCH 14\n",
      "LOSS:  0.18588728\n",
      "AUC:  0.9172118300393521\n",
      "==================================================\n",
      "EPOCH 15\n",
      "LOSS:  0.18690178\n",
      "AUC:  0.9173775261389457\n",
      "==================================================\n",
      "EPOCH 16\n",
      "LOSS:  0.185278\n",
      "AUC:  0.9189002129928762\n",
      "==================================================\n",
      "EPOCH 17\n",
      "LOSS:  0.1846408\n",
      "AUC:  0.9185826282354598\n",
      "==================================================\n",
      "EPOCH 18\n",
      "LOSS:  0.18799157\n",
      "AUC:  0.918638585425619\n",
      "==================================================\n",
      "EPOCH 19\n",
      "LOSS:  0.1852425\n",
      "AUC:  0.9184544182185461\n",
      "==================================================\n",
      "EPOCH 20\n",
      "LOSS:  0.18502957\n",
      "AUC:  0.9184051132104512\n",
      "==================================================\n",
      "EPOCH 21\n",
      "LOSS:  0.185306\n",
      "AUC:  0.9182434587278603\n",
      "==================================================\n",
      "EPOCH 22\n",
      "LOSS:  0.18588851\n",
      "AUC:  0.9176867081400703\n",
      "==================================================\n",
      "EPOCH 23\n",
      "LOSS:  0.18981041\n",
      "AUC:  0.9186405739419745\n",
      "==================================================\n",
      "EPOCH 24\n",
      "LOSS:  0.18537998\n",
      "AUC:  0.9182424967618288\n",
      "==================================================\n",
      "EPOCH 25\n",
      "LOSS:  0.1851748\n",
      "AUC:  0.9182779229455147\n",
      "==================================================\n",
      "EPOCH 26\n",
      "LOSS:  0.18500735\n",
      "AUC:  0.9185296215276875\n",
      "==================================================\n",
      "EPOCH 27\n",
      "LOSS:  0.18537101\n",
      "AUC:  0.9181019511451649\n",
      "==================================================\n",
      "EPOCH 28\n",
      "LOSS:  0.18529567\n",
      "AUC:  0.9180190011201703\n",
      "==================================================\n",
      "EPOCH 29\n",
      "LOSS:  0.18618438\n",
      "AUC:  0.9179240554127515\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-c82c8870a43b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "for epoch in tqdm(range(1000)):\n",
    "    dl = DataLoader(dataset, batch_size=batch_size, shuffle=True,num_workers=0)\n",
    "    for data,label in dl:\n",
    "        pred = nn(data)\n",
    "        loss = loss_f(pred, torch.unsqueeze(label,-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        val_pred = nn(val_tensors)\n",
    "\n",
    "        print('EPOCH {}'.format(epoch))\n",
    "        print('LOSS: ',loss_f(val_pred, torch.unsqueeze(y_val_t,-1)).detach().cpu().numpy())\n",
    "        print('AUC: ',roc_auc_score(y_val,val_pred.detach().cpu().numpy()))\n",
    "        print('='*50)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
