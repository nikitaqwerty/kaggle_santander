{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale \n",
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "input_path = \"../input/\"\n",
    "output_path = \"../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(output_path+\"nn_aug_92303_12_test.csv\")\n",
    "# np.save(output_path+\"nn_aug_92303_12_test.npy\",df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_0.9163_oof.npy',\n",
       " 'nn_0_0.92162_oof.npy',\n",
       " 'nn_0_0.92191_oof.npy',\n",
       " 'nn_0_0.92225_oof.npy',\n",
       " 'nn_0_0.92226_oof.npy',\n",
       " 'nn_0_0.92269_oof.npy',\n",
       " 'nn_0_0.92273_oof.npy',\n",
       " 'nn_0_0.9229_oof.npy',\n",
       " 'nn_0_0.92345_oof.npy',\n",
       " 'nn_1_0.92213_oof.npy',\n",
       " 'nn_1_0.92217_oof.npy',\n",
       " 'nn_1_0.92266_oof.npy',\n",
       " 'nn_1_0.92273_oof.npy',\n",
       " 'nn_1_0.92294_oof.npy',\n",
       " 'nn_1_0.92311_oof.npy',\n",
       " 'nn_1_0.923_oof.npy',\n",
       " 'nn_2_0.92128_oof.npy',\n",
       " 'nn_2_0.9228_oof.npy',\n",
       " 'nn_2_0.92314_oof.npy',\n",
       " 'nn_2_0.92316_oof.npy',\n",
       " 'nn_3_0.92114_oof.npy',\n",
       " 'nn_3_0.92172_oof.npy',\n",
       " 'nn_3_0.92235_oof.npy',\n",
       " 'nn_3_0.92269_oof.npy',\n",
       " 'nn_3_0.92287_oof.npy',\n",
       " 'nn_3_0.92333_oof.npy',\n",
       " 'nn_4_0.92263_oof.npy',\n",
       " 'nn_4_0.9227_oof.npy',\n",
       " 'nn_4_0.92292_oof.npy',\n",
       " 'nn_5_0.92241_oof.npy',\n",
       " 'nn_5_0.92248_oof.npy',\n",
       " 'nn_5_0.92258_oof.npy',\n",
       " 'nn_5_0.92286_oof.npy',\n",
       " 'nn_5_0.92289_oof.npy',\n",
       " 'nn_aug_0.92303_12_oof.npy']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npys = ([f for f in sorted(listdir(output_path)) if f.endswith(\"_oof.npy\") and f[0]!=\"!\" and \"nn\" in f \n",
    "        and (f.split(\"_\")[2]=='oof.npy' or float(f.split(\"_\")[2]) > 0.921)] )\n",
    "npys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9199_xgboost_unique_10x_upsample_0104062006.csv',\n",
       " '9202_separate_feature_models_threshold_0.84_10fold_04042353.csv',\n",
       " '9208_separate_feature_models_threshold_0.80_10fold_07041509.csv',\n",
       " '9210_lightgbm_multiplied_counter_10_folds_0604220718.csv',\n",
       " '9211_catboost_unbalanced_weights_0304111611.csv',\n",
       " '9211_catboost_unique_with_10x_upsample_3103172847.csv',\n",
       " '9211_xgboost_multiplied_counter_10_folds_0604015413.csv',\n",
       " '9212_catboost_unique_10x_upsample_5_balancer_0204172825.csv',\n",
       " '9215_catboost_unique_10x_upsample_3_balancer_0204145755.csv',\n",
       " '9218_catboost_excluded_features_10_folds_0804184027.csv',\n",
       " '9218_catboost_multiplied_counter_0304011056.csv',\n",
       " '9219_catboost_best_parameters_10_folds_0704212230.csv',\n",
       " '9222_catboost_multiplied_counter_10_folds_0504034846.csv',\n",
       " '9222_catboost_poisson_bootstrap_10_folds_0804042543.csv',\n",
       " '9223_catboost_unique_10_fold_20x_upsample_0104001611.csv',\n",
       " '9225_catboost_isotonic_09040646.csv']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../kaggle-santander-ctp-2019/predictions/train/\"\n",
    "csvs = [f for f in sorted(listdir(path)) if f.endswith(\".csv\") and \"stacking\" not in f][-16:]\n",
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:07<00:00,  4.95it/s]\n",
      "100%|██████████| 16/16 [00:06<00:00,  2.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_0.9163_oof</th>\n",
       "      <th>nn_0_0.92162_oof</th>\n",
       "      <th>nn_0_0.92191_oof</th>\n",
       "      <th>nn_0_0.92225_oof</th>\n",
       "      <th>nn_0_0.92226_oof</th>\n",
       "      <th>nn_0_0.92269_oof</th>\n",
       "      <th>nn_0_0.92273_oof</th>\n",
       "      <th>nn_0_0.9229_oof</th>\n",
       "      <th>nn_0_0.92345_oof</th>\n",
       "      <th>nn_1_0.92213_oof</th>\n",
       "      <th>...</th>\n",
       "      <th>9212_catboost_unique_10x_upsample_5_balancer_0204172825</th>\n",
       "      <th>9215_catboost_unique_10x_upsample_3_balancer_0204145755</th>\n",
       "      <th>9218_catboost_excluded_features_10_folds_0804184027</th>\n",
       "      <th>9218_catboost_multiplied_counter_0304011056</th>\n",
       "      <th>9219_catboost_best_parameters_10_folds_0704212230</th>\n",
       "      <th>9222_catboost_multiplied_counter_10_folds_0504034846</th>\n",
       "      <th>9222_catboost_poisson_bootstrap_10_folds_0804042543</th>\n",
       "      <th>9223_catboost_unique_10_fold_20x_upsample_0104001611</th>\n",
       "      <th>9225_catboost_isotonic_09040646</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.616195</td>\n",
       "      <td>0.714505</td>\n",
       "      <td>0.718645</td>\n",
       "      <td>0.722255</td>\n",
       "      <td>0.673865</td>\n",
       "      <td>0.678235</td>\n",
       "      <td>0.711385</td>\n",
       "      <td>0.688590</td>\n",
       "      <td>0.707060</td>\n",
       "      <td>0.679740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668475</td>\n",
       "      <td>0.700525</td>\n",
       "      <td>0.762780</td>\n",
       "      <td>0.75771</td>\n",
       "      <td>0.781630</td>\n",
       "      <td>0.763175</td>\n",
       "      <td>0.763940</td>\n",
       "      <td>0.725955</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.710119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0.417985</td>\n",
       "      <td>0.397495</td>\n",
       "      <td>0.380930</td>\n",
       "      <td>0.365575</td>\n",
       "      <td>0.399345</td>\n",
       "      <td>0.428905</td>\n",
       "      <td>0.363855</td>\n",
       "      <td>0.403120</td>\n",
       "      <td>0.377375</td>\n",
       "      <td>0.412225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236135</td>\n",
       "      <td>0.274450</td>\n",
       "      <td>0.377690</td>\n",
       "      <td>0.35390</td>\n",
       "      <td>0.361505</td>\n",
       "      <td>0.359545</td>\n",
       "      <td>0.360035</td>\n",
       "      <td>0.336140</td>\n",
       "      <td>0.347815</td>\n",
       "      <td>0.365214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.128315</td>\n",
       "      <td>0.040915</td>\n",
       "      <td>0.043125</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.049090</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>0.040940</td>\n",
       "      <td>0.054815</td>\n",
       "      <td>0.045875</td>\n",
       "      <td>0.031495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057385</td>\n",
       "      <td>0.050690</td>\n",
       "      <td>0.049940</td>\n",
       "      <td>0.04199</td>\n",
       "      <td>0.037920</td>\n",
       "      <td>0.045770</td>\n",
       "      <td>0.045525</td>\n",
       "      <td>0.046510</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.046262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0.801670</td>\n",
       "      <td>0.650645</td>\n",
       "      <td>0.616930</td>\n",
       "      <td>0.669095</td>\n",
       "      <td>0.675050</td>\n",
       "      <td>0.586565</td>\n",
       "      <td>0.669410</td>\n",
       "      <td>0.660420</td>\n",
       "      <td>0.652300</td>\n",
       "      <td>0.651735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751150</td>\n",
       "      <td>0.744315</td>\n",
       "      <td>0.753350</td>\n",
       "      <td>0.75148</td>\n",
       "      <td>0.744510</td>\n",
       "      <td>0.749940</td>\n",
       "      <td>0.751015</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.754415</td>\n",
       "      <td>0.686718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0.235155</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.553475</td>\n",
       "      <td>0.558465</td>\n",
       "      <td>0.561545</td>\n",
       "      <td>0.536475</td>\n",
       "      <td>0.576110</td>\n",
       "      <td>0.550650</td>\n",
       "      <td>0.568990</td>\n",
       "      <td>0.535105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634435</td>\n",
       "      <td>0.638570</td>\n",
       "      <td>0.563915</td>\n",
       "      <td>0.53344</td>\n",
       "      <td>0.562885</td>\n",
       "      <td>0.560230</td>\n",
       "      <td>0.565425</td>\n",
       "      <td>0.675020</td>\n",
       "      <td>0.561835</td>\n",
       "      <td>0.562530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        nn_0.9163_oof  nn_0_0.92162_oof  nn_0_0.92191_oof  nn_0_0.92225_oof  \\\n",
       "199995       0.616195          0.714505          0.718645          0.722255   \n",
       "199996       0.417985          0.397495          0.380930          0.365575   \n",
       "199997       0.128315          0.040915          0.043125          0.062400   \n",
       "199998       0.801670          0.650645          0.616930          0.669095   \n",
       "199999       0.235155          0.581800          0.553475          0.558465   \n",
       "\n",
       "        nn_0_0.92226_oof  nn_0_0.92269_oof  nn_0_0.92273_oof  nn_0_0.9229_oof  \\\n",
       "199995          0.673865          0.678235          0.711385         0.688590   \n",
       "199996          0.399345          0.428905          0.363855         0.403120   \n",
       "199997          0.049090          0.034770          0.040940         0.054815   \n",
       "199998          0.675050          0.586565          0.669410         0.660420   \n",
       "199999          0.561545          0.536475          0.576110         0.550650   \n",
       "\n",
       "        nn_0_0.92345_oof  nn_1_0.92213_oof  ...  \\\n",
       "199995          0.707060          0.679740  ...   \n",
       "199996          0.377375          0.412225  ...   \n",
       "199997          0.045875          0.031495  ...   \n",
       "199998          0.652300          0.651735  ...   \n",
       "199999          0.568990          0.535105  ...   \n",
       "\n",
       "        9212_catboost_unique_10x_upsample_5_balancer_0204172825  \\\n",
       "199995                                           0.668475         \n",
       "199996                                           0.236135         \n",
       "199997                                           0.057385         \n",
       "199998                                           0.751150         \n",
       "199999                                           0.634435         \n",
       "\n",
       "        9215_catboost_unique_10x_upsample_3_balancer_0204145755  \\\n",
       "199995                                           0.700525         \n",
       "199996                                           0.274450         \n",
       "199997                                           0.050690         \n",
       "199998                                           0.744315         \n",
       "199999                                           0.638570         \n",
       "\n",
       "        9218_catboost_excluded_features_10_folds_0804184027  \\\n",
       "199995                                           0.762780     \n",
       "199996                                           0.377690     \n",
       "199997                                           0.049940     \n",
       "199998                                           0.753350     \n",
       "199999                                           0.563915     \n",
       "\n",
       "        9218_catboost_multiplied_counter_0304011056  \\\n",
       "199995                                      0.75771   \n",
       "199996                                      0.35390   \n",
       "199997                                      0.04199   \n",
       "199998                                      0.75148   \n",
       "199999                                      0.53344   \n",
       "\n",
       "        9219_catboost_best_parameters_10_folds_0704212230  \\\n",
       "199995                                           0.781630   \n",
       "199996                                           0.361505   \n",
       "199997                                           0.037920   \n",
       "199998                                           0.744510   \n",
       "199999                                           0.562885   \n",
       "\n",
       "        9222_catboost_multiplied_counter_10_folds_0504034846  \\\n",
       "199995                                           0.763175      \n",
       "199996                                           0.359545      \n",
       "199997                                           0.045770      \n",
       "199998                                           0.749940      \n",
       "199999                                           0.560230      \n",
       "\n",
       "        9222_catboost_poisson_bootstrap_10_folds_0804042543  \\\n",
       "199995                                           0.763940     \n",
       "199996                                           0.360035     \n",
       "199997                                           0.045525     \n",
       "199998                                           0.751015     \n",
       "199999                                           0.565425     \n",
       "\n",
       "        9223_catboost_unique_10_fold_20x_upsample_0104001611  \\\n",
       "199995                                           0.725955      \n",
       "199996                                           0.336140      \n",
       "199997                                           0.046510      \n",
       "199998                                           0.734375      \n",
       "199999                                           0.675020      \n",
       "\n",
       "        9225_catboost_isotonic_09040646       avg  \n",
       "199995                         0.763950  0.710119  \n",
       "199996                         0.347815  0.365214  \n",
       "199997                         0.023822  0.046262  \n",
       "199998                         0.754415  0.686718  \n",
       "199999                         0.561835  0.562530  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler\n",
    "\n",
    "dt = pd.DataFrame()\n",
    "\n",
    "df = pd.read_csv(input_path+'train.csv.zip')\n",
    "df = df[[\"target\"]]\n",
    "\n",
    "cols = []\n",
    "for file in tqdm(npys):\n",
    "    train = np.load(output_path+file).reshape(-1, 1)\n",
    "    col = file[:-4]\n",
    "    cols.append(col)\n",
    "    df[col] = scaler.fit_transform(train)\n",
    "    df[col] = df[col].rank()/len(df)\n",
    "    \n",
    "    test = np.load(output_path+file.replace(\"_oof.npy\",\"_test.npy\")).reshape(-1, 1)\n",
    "    dt[col] = [x[0] for x in scaler.transform(test)]\n",
    "    dt[col] = dt[col].rank()/len(dt)\n",
    "    \n",
    "for file in tqdm(csvs):\n",
    "    train = pd.read_csv(path+file)[\"target\"].values.reshape(-1, 1)\n",
    "    col = file[:-4]\n",
    "    cols.append(col)\n",
    "    df[col] = scaler.fit_transform(train)\n",
    "    df[col] = df[col].rank()/len(df)\n",
    "    \n",
    "    test = pd.read_csv((path+file).replace(\"/train/\",\"/test/\"))[\"target\"].values.reshape(-1, 1)\n",
    "    dt[col] = [x[0] for x in scaler.transform(test)]\n",
    "    dt[col] = dt[col].rank()/len(dt)\n",
    "    \n",
    "df[\"avg\"] = df[cols].mean(axis=1)\n",
    "dt[\"avg\"] = dt[cols].mean(axis=1)\n",
    "\n",
    "dt.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[cols].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252428451998753"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df.target, df.avg)\n",
    "# 0.9252533319134989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ROC AUC: 0.92517\n",
      "1 ROC AUC: 0.92454\n",
      "2 ROC AUC: 0.9244\n",
      "3 ROC AUC: 0.92453\n",
      "4 ROC AUC: 0.93278\n",
      "5 ROC AUC: 0.92859\n",
      "6 ROC AUC: 0.93119\n",
      "7 ROC AUC: 0.92239\n",
      "8 ROC AUC: 0.92506\n",
      "9 ROC AUC: 0.92294\n",
      "\n",
      "ROC AUC: 0.92598\n",
      "CPU times: user 10.3 s, sys: 33 s, total: 43.3 s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "df[\"clf\"] = 0\n",
    "dt[\"clf\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(df[cols], df.target):\n",
    "    i+=1\n",
    "    \n",
    "    X_train = df.loc[train_index, cols]\n",
    "    X_valid = df.loc[valid_index, cols]\n",
    "\n",
    "    y_train = df.loc[train_index, \"target\"]\n",
    "    y_valid = df.loc[valid_index, \"target\"]\n",
    "    \n",
    "    clf = LogisticRegression(C=0.2,\n",
    "                             solver=\"newton-cg\", \n",
    "                             penalty=\"l2\", \n",
    "                             n_jobs=-1, \n",
    "                             max_iter=100).fit(X_train, y_train) \n",
    "    \n",
    "    y_pred = clf.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"clf\"] = y_pred\n",
    "    print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 5))\n",
    "    \n",
    "    dt[\"clf\"] += clf.predict_proba(dt[cols])[:,1] / skf.n_splits\n",
    "    \n",
    "print(\"\\nROC AUC:\", round(roc_auc_score(df.target, df[\"clf\"]), 5))\n",
    "\n",
    "# 0 ROC AUC: 0.92511\n",
    "# 1 ROC AUC: 0.92445\n",
    "# 2 ROC AUC: 0.92448\n",
    "# 3 ROC AUC: 0.92458\n",
    "# 4 ROC AUC: 0.93283\n",
    "# 5 ROC AUC: 0.92864\n",
    "# 6 ROC AUC: 0.93127\n",
    "# 7 ROC AUC: 0.92235\n",
    "# 8 ROC AUC: 0.92514\n",
    "# 9 ROC AUC: 0.92289\n",
    "\n",
    "# ROC AUC: 0.92597\n",
    "# CPU times: user 10.1 s, sys: 33 s, total: 43.1 s\n",
    "# Wall time: 2min 39s\n",
    "\n",
    "# 0 ROC AUC: 0.92516\n",
    "# 1 ROC AUC: 0.9245\n",
    "# 2 ROC AUC: 0.92443\n",
    "# 3 ROC AUC: 0.92452\n",
    "# 4 ROC AUC: 0.93274\n",
    "# 5 ROC AUC: 0.92859\n",
    "# 6 ROC AUC: 0.9312\n",
    "# 7 ROC AUC: 0.9224\n",
    "# 8 ROC AUC: 0.92507\n",
    "# 9 ROC AUC: 0.92297\n",
    "\n",
    "# ROC AUC: 0.92598\n",
    "# CPU times: user 10.3 s, sys: 33 s, total: 43.3 s\n",
    "# Wall time: 2min 36s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_train = df[\"clf\"] \n",
    "# clf_test =  dt[\"clf\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clf_\"] = clf_train \n",
    "dt[\"clf_\"] = clf_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg\"] = (df[\"clf_\"].rank()+df[\"clf\"].rank())/2\n",
    "dt[\"avg\"] = (dt[\"clf_\"].rank()+dt[\"clf\"].rank())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC AUC: 0.92598\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nROC AUC:\", round(roc_auc_score(df.target, df[\"avg\"]), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# df[\"clf\"] = 0\n",
    "# dt[\"clf\"] = 0\n",
    "\n",
    "# i = -1\n",
    "# for train_index, valid_index in skf.split(df[cols], df.target):\n",
    "#     i+=1\n",
    "    \n",
    "#     X_train = df.loc[train_index, cols]\n",
    "#     X_valid = df.loc[valid_index, cols]\n",
    "\n",
    "#     y_train = df.loc[train_index, \"target\"]\n",
    "#     y_valid = df.loc[valid_index, \"target\"]\n",
    "    \n",
    "#     clf = LogisticRegression(C=0.5,\n",
    "#                              solver=\"newton-cg\", \n",
    "#                              penalty=\"l2\", \n",
    "#                              n_jobs=-1, \n",
    "#                              max_iter=100).fit(X_train, y_train) \n",
    "    \n",
    "#     y_pred = clf.predict_proba(X_valid)[:,1] \n",
    "#     df.loc[valid_index, \"clf\"] = y_pred\n",
    "#     print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 4))\n",
    "    \n",
    "#     dt[\"clf\"] += clf.predict_proba(dt[cols])[:,1] / skf.n_splits\n",
    "    \n",
    "# print(\"\\nROC AUC:\", round(roc_auc_score(df.target, df[\"clf\"]), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# df[\"svc\"] = 0\n",
    "# dt[\"svc\"] = 0\n",
    "\n",
    "# i = -1\n",
    "# for train_index, valid_index in skf.split(df[cols], df.target):\n",
    "#     i+=1\n",
    "    \n",
    "#     X_train = df.loc[train_index, cols]\n",
    "#     X_valid = df.loc[valid_index, cols]\n",
    "\n",
    "#     y_train = df.loc[train_index, \"target\"]\n",
    "#     y_valid = df.loc[valid_index, \"target\"]\n",
    "    \n",
    "#     svc = SVC(C=10, probability=True).fit(X_train, y_train)  \n",
    "    \n",
    "#     y_pred = svc.predict_proba(X_valid)[:,1] \n",
    "#     df.loc[valid_index, \"svc\"] = y_pred\n",
    "#     print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 4))\n",
    "    \n",
    "#     dt[\"svc\"] += svc.predict_proba(dt[cols].values) / skf.n_splits\n",
    "    \n",
    "# print(\"\\nROC AUC:\", round(roc_auc_score(df.target, df[\"svc\"]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# df[\"nei\"] = 0\n",
    "# dt[\"nei\"] = 0\n",
    "\n",
    "# i = -1\n",
    "# for train_index, valid_index in skf.split(df[cols], df.target):\n",
    "#     i+=1\n",
    "    \n",
    "#     X_train = df.loc[train_index, cols]\n",
    "#     X_valid = df.loc[valid_index, cols]\n",
    "\n",
    "#     y_train = df.loc[train_index, \"target\"]\n",
    "#     y_valid = df.loc[valid_index, \"target\"]\n",
    "    \n",
    "#     nei = KNeighborsClassifier(n_neighbors=5000, p=1, n_jobs=-1).fit(X_train, y_train) \n",
    "    \n",
    "#     y_pred = nei.predict_proba(X_valid)[:,1] \n",
    "#     df.loc[valid_index, \"nei\"] = y_pred\n",
    "#     print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 4))\n",
    "    \n",
    "#     dt[\"nei\"] += nei.predict_proba(dt[cols])[:,1] / skf.n_splits\n",
    "    \n",
    "# print(\"\\nROC AUC:\", round(roc_auc_score(df.target, df[\"nei\"]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 ROC AUC: 0.9232\n",
    "# 1 ROC AUC: 0.9232\n",
    "# 2 ROC AUC: 0.9293\n",
    "# 3 ROC AUC: 0.9247\n",
    "# 4 ROC AUC: 0.9216\n",
    "\n",
    "# ROC AUC: 0.9243\n",
    "# CPU times: user 7h 3min 54s, sys: 7min 15s, total: 7h 11min 9s\n",
    "# Wall time: 31min 9s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 10000\n",
    "early_stop_rounds = 500\n",
    "\n",
    "param_grid = {'num_leaves': list(range(10, 30)),\n",
    "              'max_bin': [511, 1023, 2047],\n",
    "              'min_data_in_leaf': list(range(10, 100, 10)),\n",
    "              'min_sum_hessian_in_leaf': list(range(0, 10)),\n",
    "              'learning_rate': np.linspace(0.01, 0.03, 31),\n",
    "              \"bagging_freq\": list(range(1, 5)),\n",
    "              \"bagging_fraction\": np.linspace(0.5, 1.0, 51),\n",
    "              'feature_fraction': np.linspace(0.08, 1.0, 11),\n",
    "              'lambda_l1': np.linspace(0, 3, 61),\n",
    "              'lambda_l2': np.linspace(0, 3, 61)}\n",
    "\n",
    "param_static = {'boosting_type': 'gbrt',\n",
    "                'objective': 'binary',\n",
    "                'tree_learner': 'serial',\n",
    "                'metric': 'auc',\n",
    "                'bagging_seed': 42,\n",
    "                'seed': 42,\n",
    "                'max_depth': -1,\n",
    "                'verbose': -1,\n",
    "                'n_jobs': -1}\n",
    "\n",
    "param_list = list(ParameterSampler(param_grid, n_iter=100))\n",
    "\n",
    "rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
    "                for d in param_list]\n",
    "\n",
    "results = []\n",
    "for i, params in enumerate(rounded_list):\n",
    "    print(params)\n",
    "\n",
    "    for key in param_static:\n",
    "        params[key] = param_static[key]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    oof = np.zeros(len(df))\n",
    "    res = 0\n",
    "\n",
    "    j = 0\n",
    "    for train_index, valid_index in skf.split(df[cols], df.target):\n",
    "        j += 1\n",
    "\n",
    "        X_train = df.loc[train_index, cols]\n",
    "        X_valid = df.loc[valid_index, cols]\n",
    "\n",
    "        y_train = df.loc[train_index, \"target\"]\n",
    "        y_valid = df.loc[valid_index, \"target\"]\n",
    "\n",
    "        d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "        d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)\n",
    "\n",
    "        model = lgb.train(params,\n",
    "                          d_train,\n",
    "                          num_boost_round=rounds,\n",
    "                          valid_sets=[d_train, d_valid],\n",
    "                          valid_names=['train', 'valid'],\n",
    "                          early_stopping_rounds=early_stop_rounds,\n",
    "                          verbose_eval=0)\n",
    "\n",
    "        oof[valid_index] = model.predict(X_valid)\n",
    "        auc = round(roc_auc_score(y_valid, oof[valid_index]), 4)\n",
    "        print(i, j, \"CV score: {:<8.4f}\".format(auc))\n",
    "    \n",
    "    res = round(roc_auc_score(df.target, oof), 4)\n",
    "    print(\"\\noof CV score: {:<8.4f}\".format(res))\n",
    "    \n",
    "    results.append((params, res))\n",
    "    for key in param_static:\n",
    "        del params[key]\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    print(\"best:\", sorted_results[0])\n",
    "    \n",
    "# 0 ROC AUC: 0.9236\n",
    "# 1 ROC AUC: 0.9234\n",
    "# 2 ROC AUC: 0.9299\n",
    "# 3 ROC AUC: 0.9252\n",
    "# 4 ROC AUC: 0.9222\n",
    "\n",
    "# ROC AUC: 0.9246"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator(df, vcs_train_test):\n",
    "    for i in tqdm(range(200)):\n",
    "        col = \"var_\" + str(i)\n",
    "        vtraintest = vcs_train_test[col]\n",
    "        t = vtraintest[df[col]].fillna(0).values\n",
    "\n",
    "        df[col + '_train_test_sum_vcs'] = t\n",
    "        df[col + '_train_test_sum_vcs_prod'] = df[col] * t\n",
    "        df[col + '_train_test_sum_vcs_unique'] = np.array(t == 1).astype(int)\n",
    "        df[col + '_train_test_sum_vcs_minus'] = scale(df[col]) - scale(t)\n",
    "        df[col + '_train_test_sum_vcs_plus'] = scale(df[col]) + scale(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_path + 'train.csv.zip')\n",
    "\n",
    "label = train_df.target\n",
    "train = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "\n",
    "test = pd.read_csv(input_path + 'test.csv.zip')\n",
    "test = test.drop(['ID_code'], axis=1)\n",
    "\n",
    "test_filtered = pd.read_pickle(input_path + 'test_filtered.pkl')\n",
    "test_filtered = test_filtered.loc[:, train.columns]\n",
    "\n",
    "train_test = pd.concat([train, test_filtered]).reset_index(drop=True)\n",
    "\n",
    "vcs_train_test = {}\n",
    "\n",
    "for col in tqdm(train.columns):\n",
    "    vcs_train_test[col] = train_test.loc[:, col].value_counts()\n",
    "\n",
    "feature_generator(train, vcs_train_test)\n",
    "feature_generator(test, vcs_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(list(train.columns)):\n",
    "    df[col] = list(train[col])\n",
    "    dt[col] = list(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove(\"target\")\n",
    "cols.remove(\"avg\")\n",
    "cols.remove(\"clf\")\n",
    "cols.remove(\"blend\")\n",
    "cols.remove(\"lgb\")\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rounds = 10000\n",
    "early_stop_rounds = 300\n",
    "\n",
    "params = {'num_leaves': 20, \n",
    "             'min_sum_hessian_in_leaf': 2, \n",
    "             'min_data_in_leaf': 10, \n",
    "             'max_bin': 1023, \n",
    "             'learning_rate': 0.01, \n",
    "             'lambda_l2': 0, \n",
    "             'lambda_l1': 1, \n",
    "             'feature_fraction': 0.1, \n",
    "             'bagging_freq': 2, \n",
    "             'bagging_fraction': 0.7,\n",
    "             'boosting_type': 'gbrt',\n",
    "             'objective': 'binary',\n",
    "             'tree_learner': 'serial',\n",
    "             'metric': 'auc',\n",
    "             'bagging_seed': 42,\n",
    "             'seed': 42,\n",
    "             'max_depth': -1,\n",
    "             'verbose': -1,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "df[\"lgb\"] = 0\n",
    "dt[\"lgb\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(df[cols], df.target):\n",
    "    i+=1\n",
    "    \n",
    "    X_train = df.loc[train_index, cols]\n",
    "    X_valid = df.loc[valid_index, cols]\n",
    "\n",
    "    y_train = df.loc[train_index, \"target\"]\n",
    "    y_valid = df.loc[valid_index, \"target\"]\n",
    "    \n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      d_train,\n",
    "                      num_boost_round=rounds,\n",
    "                      valid_sets=[d_train, d_valid],\n",
    "                      valid_names=['train','valid'],\n",
    "                      early_stopping_rounds=early_stop_rounds,\n",
    "                      verbose_eval=50) \n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    df.loc[valid_index, \"lgb\"] = y_pred\n",
    "    print(i, \"ROC AUC:\", round(roc_auc_score(y_valid, y_pred), 4))\n",
    "    \n",
    "    dt[\"lgb\"] += model.predict(dt[cols]) / skf.n_splits\n",
    "    \n",
    "print(\"\\nROC AUC:\", round(roc_auc_score(df.target, df[\"lgb\"]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 ROC AUC: 0.9239\n",
    "# 1 ROC AUC: 0.9239\n",
    "# 2 ROC AUC: 0.93\n",
    "# 3 ROC AUC: 0.9259\n",
    "# 4 ROC AUC: 0.923\n",
    "\n",
    "# ROC AUC: 0.9243\n",
    "# CPU times: user 3h 14min 48s, sys: 49.2 s, total: 3h 15min 37s\n",
    "# Wall time: 8min 33s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 100))\n",
    "lgb.plot_importance(model, max_num_features=len(cols), ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC AUC: 0.92598\n"
     ]
    }
   ],
   "source": [
    "w = [0,1]\n",
    "\n",
    "df[\"blend\"] = (w[1]*df[\"clf\"])/sum(w)\n",
    "dt[\"blend\"] = (w[1]*dt[\"clf\"])/sum(w)\n",
    "\n",
    "print(\"\\nROC AUC:\", round(roc_auc_score(df.target, df[\"blend\"]), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.117465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.369864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.346955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.176855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.051232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.117465\n",
       "1  test_1  0.369864\n",
       "2  test_2  0.346955\n",
       "3  test_3  0.176855\n",
       "4  test_4  0.051232"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(input_path+'sample_submission.csv.zip')\n",
    "sub[\"target\"] = dt[\"blend\"]\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(output_path + \"best_blend_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best_auc_nn_0.pkl\t  nn_0_0.92226_test.npy   nn_3_0.92114_test.npy\r\n",
      " best_auc_nn_1.pkl\t  nn_0_0.92269_oof.npy\t  nn_3_0.92172_oof.npy\r\n",
      " best_auc_nn_2.pkl\t  nn_0_0.92269_test.npy   nn_3_0.92172_test.npy\r\n",
      " best_auc_nn_3.pkl\t  nn_0_0.92273_oof.npy\t  nn_3_0.92235_oof.npy\r\n",
      " best_auc_nn.pkl\t  nn_0_0.92273_test.npy   nn_3_0.92235_test.npy\r\n",
      " best_blend_10.csv\t  nn_0_0.9229_oof.npy\t  nn_3_0.92269_oof.npy\r\n",
      " best_blend_13.csv\t  nn_0_0.9229_test.npy\t  nn_3_0.92269_test.npy\r\n",
      " best_blend_19.csv\t  nn_0_0.92345_oof.npy\t  nn_3_0.92287_oof.npy\r\n",
      " best_blend_25.csv\t  nn_0_0.92345_test.npy   nn_3_0.92287_test.npy\r\n",
      " best_blend_33.csv\t  nn_0.9163_oof.npy\t  nn_3_0.92333_oof.npy\r\n",
      " best_blend_47.csv\t  nn_0.9163_test.npy\t  nn_3_0.92333_test.npy\r\n",
      " best_blend_7.csv\t  nn_1_0.92213_oof.npy\t  nn_4_0.92096_oof.npy\r\n",
      " best_blend_8.csv\t  nn_1_0.92213_test.npy   nn_4_0.92096_test.npy\r\n",
      " best_blend_.csv\t  nn_1_0.92217_oof.npy\t  nn_4_0.92263_oof.npy\r\n",
      " best_blend.csv\t\t  nn_1_0.92217_test.npy   nn_4_0.92263_test.npy\r\n",
      "'!cat_0.91558_oof.npy'\t  nn_1_0.92266_oof.npy\t  nn_4_0.9227_oof.npy\r\n",
      "'!cat_0.91558_test.npy'   nn_1_0.92266_test.npy   nn_4_0.9227_test.npy\r\n",
      " cat_0.91617_oof.npy\t  nn_1_0.92273_oof.npy\t  nn_4_0.92292_oof.npy\r\n",
      " cat_0.91617_test.npy\t  nn_1_0.92273_test.npy   nn_4_0.92292_test.npy\r\n",
      " data_1_cont.pkl\t  nn_1_0.92294_oof.npy\t  nn_5_0.92241_oof.npy\r\n",
      " hpo_logs_0.json\t  nn_1_0.92294_test.npy   nn_5_0.92241_test.npy\r\n",
      " hpo_logs_1.json\t  nn_1_0.92311_oof.npy\t  nn_5_0.92248_oof.npy\r\n",
      " hpo_logs_2.json\t  nn_1_0.92311_test.npy   nn_5_0.92248_test.npy\r\n",
      " hpo_logs_3.json\t  nn_1_0.923_oof.npy\t  nn_5_0.92258_oof.npy\r\n",
      " hpo_logs_4.json\t  nn_1_0.923_test.npy\t  nn_5_0.92258_test.npy\r\n",
      " hpo_logs_5.json\t  nn_2_0.92013_oof.npy\t  nn_5_0.92286_oof.npy\r\n",
      " lgb_0.91145_oof.npy\t  nn_2_0.92013_test.npy   nn_5_0.92286_test.npy\r\n",
      " lgb_0.91145_test.npy\t  nn_2_0.92128_oof.npy\t  nn_5_0.92289_oof.npy\r\n",
      " lgb_0.91305_oof.npy\t  nn_2_0.92128_test.npy   nn_5_0.92289_test.npy\r\n",
      " lgb_0.91305_test.npy\t  nn_2_0.9228_oof.npy\t  nn_aug_0.92303_12_oof.npy\r\n",
      " models\t\t\t  nn_2_0.9228_test.npy\t  nn_aug_0.92303_12_test.npy\r\n",
      " nn_0_0.92162_oof.npy\t  nn_2_0.92314_oof.npy\t  predictions\r\n",
      " nn_0_0.92162_test.npy\t  nn_2_0.92314_test.npy   train_1.bin\r\n",
      " nn_0_0.92191_oof.npy\t  nn_2_0.92316_oof.npy\t  train_1.feather\r\n",
      " nn_0_0.92191_test.npy\t  nn_2_0.92316_test.npy   train_1.npy\r\n",
      " nn_0_0.92225_oof.npy\t  nn_3_0.91834_oof.npy\t  valid_1.bin\r\n",
      " nn_0_0.92225_test.npy\t  nn_3_0.91834_test.npy   xgb_0.91221_oof.npy\r\n",
      " nn_0_0.92226_oof.npy\t  nn_3_0.92114_oof.npy\t  xgb_0.91221_test.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 6.17M/6.17M [00:05<00:00, 1.22MB/s]\n",
      "Successfully submitted to Santander Customer Transaction Prediction"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c santander-customer-transaction-prediction -f ../output/best_blend_.csv -m \"0.92598 10-folds reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0\n",
    "ans = {}\n",
    "for i in range(6):\n",
    "    with open(f\"../output/hpo_logs_{i}.json\" ,\"r\") as f:\n",
    "        for item in f.readlines():\n",
    "            d = eval(item)\n",
    "            ans[d[\"target\"]] = (d[\"params\"],i)\n",
    "            if d[\"target\"]>=res:\n",
    "                res = d[\"target\"]\n",
    "                print(i, res, d[\"params\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in sorted(ans)[-4:]:\n",
    "    print(score, ans[score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sorted(ans)[-4 - 1]\n",
    "params = ans[score]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
