{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ParameterSampler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import fbeta_score, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.observer import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.util import load_logs\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "input_path = \"../input/\"\n",
    "output_path = \"../output/\"\n",
    "model_path = \"../models/\"\n",
    "\n",
    "ensure_dir(model_path)\n",
    "ensure_dir(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_path+'train.csv.zip')\n",
    "\n",
    "label = train_df.target\n",
    "train = train_df.drop(['ID_code','target'],axis=1)\n",
    "\n",
    "test = pd.read_csv(input_path+'test.csv.zip')\n",
    "test = test.drop(['ID_code'],axis=1)\n",
    "\n",
    "test_filtered = pd.read_pickle(input_path+'test_filtered.pkl')\n",
    "test_filtered = test_filtered.loc[:,train.columns]\n",
    "\n",
    "train_test = pd.concat([train,test_filtered]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ee9668f7d34872ad1ca4b9f94c362e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vcs_train_test = {}\n",
    "vcs_train_test_3 = {}\n",
    "\n",
    "for i in tqdm(range(200)):\n",
    "    col = \"var_\"+str(i)\n",
    "    tmp = train_test.loc[:,col].apply(lambda x: round(x,3))\n",
    "    vcs_train_test[col] = train_test.loc[:,col].value_counts()\n",
    "    vcs_train_test_3[col] = tmp.value_counts()# /300000\n",
    "#     vtraintest = vcs_train_test[col]\n",
    "#     t = vtraintest[train_test[col]].values\n",
    "#     train_test[col+'_train_test_sum_vcs'] = t\n",
    "#     train_test[col+'_train_test_sum_vcs_prod'] = train_test[col]*t\n",
    "#     vcs_train_test_prod[col] = train_test.loc[:,col+'_train_test_sum_vcs_prod'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0775b443e0494624a1dc06c48c009b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec337ed017754407b546356c38f2f81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def feature_generator(df):\n",
    "    for i in tqdm(range(200)):\n",
    "        col = \"var_\"+str(i)\n",
    "        \n",
    "        vtraintest = vcs_train_test[col]\n",
    "        t = vtraintest[df[col]].values #fillna(0).values\n",
    "        df[col+'_train_test_sum_vcs'] = t\n",
    "        df[col+'_train_test_sum_vcs_prod'] = df[col]*t\n",
    "        \n",
    "        vtraintest = vcs_train_test_3[col]\n",
    "        t = vtraintest[df[col].apply(lambda x: round(x,3))].values #fillna(0).values\n",
    "        df[col+'_train_test_sum_vcs_3'] = t\n",
    "        df[col+'_train_test_sum_vcs_prod_3'] = df[col].apply(lambda x: round(x,3))*t\n",
    "        \n",
    "#         vtraintest_prod = vcs_train_test_prod[col]\n",
    "#         t = vtraintest_prod[df[col]].values #fillna(0).values\n",
    "#         df[col+'_train_test_sum_vcs_'] = t\n",
    "#         df[col+'_train_test_sum_vcs_prod_'] = df[col]*t\n",
    "        \n",
    "#         df[col+'_train_test_sum_vcs_sign'] = (df[col+\"_train_test_sum_vcs_prod\"]>0).astype(int)\n",
    "#         df[col+'_train_test_sum_vcs_div'] = df[col]/t\n",
    "#         df[col+'_train_test_sum_vcs_minus'] = scale(df[col]) - scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_plus'] = scale(df[col]) + scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_min'] = np.min(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_max'] = np.max(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_pow'] = np.power(abs(scale(df[col])), abs(scale(t)))\n",
    "#         df[col+'_train_test_sum_vcs_log'] = np.log(abs(scale(df[col])), abs(scale(t)))\n",
    "        \n",
    "feature_generator(train)\n",
    "feature_generator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train\n",
    "dt = test\n",
    "\n",
    "cols = sorted(list(set(df.columns)-{\"label\"}))\n",
    "print(len(cols))\n",
    "\n",
    "df[\"label\"] = label\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2212.056    255\n",
       "2729.290    174\n",
       "2630.294    169\n",
       "2746.520    167\n",
       "2539.890    167\n",
       "2771.922    163\n",
       "2699.305    163\n",
       "2622.296    163\n",
       "2652.239    162\n",
       "2524.032    162\n",
       "2667.151    161\n",
       "2693.247    160\n",
       "2662.584    159\n",
       "2620.695    159\n",
       "2768.849    158\n",
       "2454.898    158\n",
       "2609.152    158\n",
       "2644.568    158\n",
       "2748.394    158\n",
       "2596.631    157\n",
       "2563.385    156\n",
       "2262.029    156\n",
       "2555.411    156\n",
       "2551.003    156\n",
       "2564.946    155\n",
       "2593.475    155\n",
       "2581.225    155\n",
       "2594.932    154\n",
       "2402.610    154\n",
       "2636.136    154\n",
       "           ... \n",
       "12.768        1\n",
       "38.715        1\n",
       "38.730        1\n",
       "20.084        1\n",
       "13.057        1\n",
       "12.922        1\n",
       "9.922         1\n",
       "12.974        1\n",
       "26.038        1\n",
       "10.017        1\n",
       "19.948        1\n",
       "13.160        1\n",
       "13.040        1\n",
       "20.022        1\n",
       "60.198        1\n",
       "20.154        1\n",
       "9.975         1\n",
       "12.970        1\n",
       "12.904        1\n",
       "12.863        1\n",
       "12.856        1\n",
       "19.920        1\n",
       "9.842         1\n",
       "12.877        1\n",
       "30.015        1\n",
       "9.880         1\n",
       "12.900        1\n",
       "12.980        1\n",
       "12.827        1\n",
       "20.118        1\n",
       "Name: var_34_train_test_sum_vcs_prod_3, Length: 2956, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.var_34_train_test_sum_vcs_prod_3.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"clf\"] = 0\n",
    "dt[\"clf\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'clf_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 1\n",
    "        clf = LogisticRegression(C=c,\n",
    "                                 solver=\"newton-cg\",\n",
    "                                 penalty=\"l2\", \n",
    "                                 n_jobs=-1, \n",
    "                                 max_iter=1000).fit(X_train, y_train) \n",
    "        joblib.dump(clf, fname)\n",
    "    else:\n",
    "        clf = joblib.load(fname)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"clf\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"clf\"] += clf.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"clf\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"clf\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"clf\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"svc\"] = 0\n",
    "dt[\"svc\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'svc_'+str(i)+'.pkl'\n",
    "    #print(fname)\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 100\n",
    "        svc = SVC(C=c,\n",
    "                  probability=True).fit(X_train, y_train) \n",
    "        \n",
    "        joblib.dump(svc, fname)\n",
    "    else:\n",
    "        svc = joblib.load(fname)\n",
    "\n",
    "    y_pred = svc.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"svc\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"svc\"] += svc.predict(Z)/5\n",
    "\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"svc\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"svc\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"svc\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"nei\"] = 0\n",
    "dt[\"nei\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'nei_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        nei = KNeighborsClassifier(n_neighbors=50,\n",
    "                                   p=1, n_jobs=-1).fit(X_train, y_train) \n",
    "        joblib.dump(nei, fname)\n",
    "    else:\n",
    "        nei = joblib.load(fname)\n",
    "\n",
    "    y_pred = nei.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"nei\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"nei\"] += nei.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"nei\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"nei\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"nei\"]\n",
    "\n",
    "# k = 0\n",
    "# cols = [f\"var_{k}\",\n",
    "#         f\"var_{k}_train_test_sum_vcs\",\n",
    "#         f\"var_{k}_train_test_sum_vcs_prod\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "#Z = dt[cols # ]scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 10000\n",
    "early_stop_rounds = 200\n",
    "\n",
    "params = {'lambda_l1': 0, \n",
    "          'lambda_l2': 0,\n",
    "          'feature_fraction':0.9,\n",
    "#           'bagging_fraction':0.1,\n",
    "#           'bagging_freq': 1,\n",
    "          'learning_rate': 0.03, \n",
    "          'max_depth': 4,\n",
    "          #'min_data_in_leaf':20,\n",
    "          #'num_leaves':2**5-1,\n",
    "          'boosting_type': 'gbrt', #dart gbrt\n",
    "          'objective': 'binary', \n",
    "          'metric': 'auc',\n",
    "          #'weight': [1, 0.5],\n",
    "          #'device': 'gpu',\n",
    "          #'gpu_platform_id': '0',\n",
    "          #'gpu_device_id': '0',\n",
    "          'max_bin': 1024,\n",
    "          'n_jobs':-1\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttrain's auc: 0.842046\tvalid's auc: 0.809278\n",
      "[200]\ttrain's auc: 0.88315\tvalid's auc: 0.845162\n",
      "[300]\ttrain's auc: 0.90458\tvalid's auc: 0.863268\n",
      "[400]\ttrain's auc: 0.918961\tvalid's auc: 0.87402\n",
      "[500]\ttrain's auc: 0.929144\tvalid's auc: 0.881456\n",
      "[600]\ttrain's auc: 0.937068\tvalid's auc: 0.886814\n",
      "[700]\ttrain's auc: 0.94321\tvalid's auc: 0.891072\n",
      "[800]\ttrain's auc: 0.948354\tvalid's auc: 0.894293\n",
      "[900]\ttrain's auc: 0.952496\tvalid's auc: 0.896859\n",
      "[1000]\ttrain's auc: 0.956152\tvalid's auc: 0.898978\n",
      "[1100]\ttrain's auc: 0.959277\tvalid's auc: 0.900682\n",
      "[1200]\ttrain's auc: 0.962134\tvalid's auc: 0.90222\n",
      "[1300]\ttrain's auc: 0.964719\tvalid's auc: 0.903434\n",
      "[1400]\ttrain's auc: 0.967117\tvalid's auc: 0.904579\n",
      "[1500]\ttrain's auc: 0.969281\tvalid's auc: 0.905521\n",
      "[1600]\ttrain's auc: 0.97123\tvalid's auc: 0.906321\n",
      "[1700]\ttrain's auc: 0.973155\tvalid's auc: 0.907039\n",
      "[1800]\ttrain's auc: 0.974857\tvalid's auc: 0.907663\n",
      "[1900]\ttrain's auc: 0.976385\tvalid's auc: 0.908186\n",
      "[2000]\ttrain's auc: 0.97782\tvalid's auc: 0.908667\n",
      "[2100]\ttrain's auc: 0.979189\tvalid's auc: 0.909099\n",
      "[2200]\ttrain's auc: 0.980458\tvalid's auc: 0.909524\n",
      "[2300]\ttrain's auc: 0.981717\tvalid's auc: 0.909799\n",
      "[2400]\ttrain's auc: 0.982817\tvalid's auc: 0.910125\n",
      "[2500]\ttrain's auc: 0.983914\tvalid's auc: 0.910346\n",
      "[2600]\ttrain's auc: 0.98486\tvalid's auc: 0.910404\n",
      "[2700]\ttrain's auc: 0.985772\tvalid's auc: 0.910668\n",
      "[2800]\ttrain's auc: 0.986624\tvalid's auc: 0.910741\n",
      "[2900]\ttrain's auc: 0.987451\tvalid's auc: 0.910835\n",
      "[3000]\ttrain's auc: 0.988272\tvalid's auc: 0.910918\n",
      "[3100]\ttrain's auc: 0.989022\tvalid's auc: 0.911059\n",
      "[3200]\ttrain's auc: 0.989721\tvalid's auc: 0.911147\n",
      "[3300]\ttrain's auc: 0.990419\tvalid's auc: 0.911086\n",
      "[3400]\ttrain's auc: 0.991031\tvalid's auc: 0.911197\n",
      "[3500]\ttrain's auc: 0.991612\tvalid's auc: 0.911306\n",
      "[3600]\ttrain's auc: 0.99216\tvalid's auc: 0.911325\n",
      "[3700]\ttrain's auc: 0.992652\tvalid's auc: 0.91145\n",
      "[3800]\ttrain's auc: 0.993122\tvalid's auc: 0.911489\n",
      "[3900]\ttrain's auc: 0.993597\tvalid's auc: 0.911586\n",
      "[4000]\ttrain's auc: 0.994051\tvalid's auc: 0.911564\n",
      "Early stopping, best iteration is:\n",
      "[3884]\ttrain's auc: 0.993532\tvalid's auc: 0.911628\n",
      "ROC AUC: 0.9116 \n",
      "F-score: 0.5129 0\n",
      "CPU times: user 2h 39min, sys: 40.5 s, total: 2h 39min 40s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df[\"lgb\"] = 0\n",
    "dt[\"lgb\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    fname = model_path+'lgb_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        model = lgb.train(params,\n",
    "                            d_train,\n",
    "                            num_boost_round=rounds,\n",
    "                            valid_sets=[d_train, d_valid],\n",
    "                            valid_names=['train','valid'],\n",
    "                            #feval=lgb_f1_score,\n",
    "                            early_stopping_rounds=early_stop_rounds,\n",
    "                            verbose_eval=100)\n",
    "        \n",
    "        joblib.dump(model, fname)\n",
    "    else:\n",
    "        model = joblib.load(fname)\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    df.loc[valid_index, \"lgb\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    #dt[\"lgb\"] += model.predict(Z)/5\n",
    "    break\n",
    "    \n",
    "# print(\"\\nROC AUC:\", round(auc(df.label, df[\"lgb\"]), 4), \n",
    "#       \"\\nF-score:\", round(fbeta_score(df.label, df[\"lgb\"]>0.5, beta=1), 4))\n",
    "\n",
    "# [3992]\ttrain's auc: 0.989264\tvalid's auc: 0.913532\n",
    "# ROC AUC: 0.9135 \n",
    "# F-score: 0.5195 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13        0.121532\n",
       "84        0.113602\n",
       "525       0.102129\n",
       "577       0.141882\n",
       "1312      0.101255\n",
       "1423      0.105894\n",
       "1490      0.125100\n",
       "1858      0.160463\n",
       "1863      0.107850\n",
       "2093      0.115804\n",
       "2118      0.101529\n",
       "2214      0.107850\n",
       "2301      0.103038\n",
       "2392      0.106306\n",
       "2682      0.128267\n",
       "2684      0.149859\n",
       "2718      0.102518\n",
       "2827      0.116290\n",
       "3134      0.255105\n",
       "3219      0.206279\n",
       "3388      0.141882\n",
       "3396      0.123623\n",
       "3444      0.239903\n",
       "3842      0.107250\n",
       "3986      0.107850\n",
       "4103      0.112789\n",
       "4251      0.154898\n",
       "4333      0.206279\n",
       "4600      0.111623\n",
       "4940      0.246335\n",
       "            ...   \n",
       "196368    0.103798\n",
       "196577    0.135669\n",
       "196700    0.110354\n",
       "196771    0.106646\n",
       "196803    0.226802\n",
       "196806    0.161413\n",
       "197057    0.129187\n",
       "197513    0.113602\n",
       "197752    0.107044\n",
       "197926    0.118239\n",
       "198089    0.118239\n",
       "198250    0.116290\n",
       "198584    0.116535\n",
       "198643    0.113762\n",
       "198689    0.110793\n",
       "198733    0.113840\n",
       "198815    0.105201\n",
       "198916    0.136829\n",
       "198929    0.113416\n",
       "199023    0.125083\n",
       "199103    0.161789\n",
       "199131    0.108088\n",
       "199229    0.118688\n",
       "199268    0.116341\n",
       "199333    0.112789\n",
       "199561    0.204370\n",
       "199596    0.113227\n",
       "199730    0.113207\n",
       "199892    0.107277\n",
       "199966    0.102518\n",
       "Name: lgb, Length: 1398, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[valid_index, \"lgb\"][df.label==1][df.lgb>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1,2,5]\n",
    "\n",
    "df[\"avg\"] = (w[0]*df[\"clf\"]+w[1]*df[\"svc\"]+w[2]*df[\"lgb\"])/sum(w)\n",
    "dt[\"avg\"] = (w[0]*dt[\"clf\"]+w[1]*dt[\"svc\"]+w[2]*dt[\"lgb\"])/sum(w)\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"avg\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"avg\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dt[\"avg\"] > 0.5) / len(dt), np.sum(df[\"avg\"] > 0.5) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(dt[\"avg\"] > 0.5)\n",
    "np.mean(predictions[:2*len(predictions)//5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[[\"Image\",\"avg\"]].to_csv(\"test_prediction_top5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 300))\n",
    "lgb.plot_importance(model, max_num_features=len(cols), ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]>0.5)&(df.label!=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]<0.5)&(df.label==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "              'max_depth': [3,4,5],\n",
    "              'learning_rate': np.linspace(0.01, 0.1, 10),\n",
    "              'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "              'lambda_l1': np.linspace(1, 10, 10),\n",
    "              'lambda_l2': np.linspace(1, 10, 10)\n",
    "            }\n",
    "\n",
    "param_static = {\n",
    "                'boosting_type': 'gbrt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'max_bin': 1024,\n",
    "                'n_jobs': -1\n",
    "               }\n",
    "\n",
    "param_list = list(ParameterSampler(param_grid, \n",
    "                                   n_iter=10))\n",
    "\n",
    "rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
    "                for d in param_list]\n",
    "\n",
    "rounds = 10000\n",
    "early_stop_rounds = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, valid_index in skf.split(X, y):\n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    break\n",
    "\n",
    "results = []\n",
    "for i, params in enumerate(rounded_list):\n",
    "    print(params)\n",
    "    start_time = datetime.datetime.fromtimestamp(time.time())\n",
    "    \n",
    "    for key in param_static:\n",
    "        params[key] = param_static[key]\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      d_train,\n",
    "                      num_boost_round=rounds,\n",
    "                      valid_sets=[d_train, d_valid],\n",
    "                      valid_names=['train','valid'],\n",
    "                      #feval=lgb_f1_score,\n",
    "                      early_stopping_rounds=early_stop_rounds,\n",
    "                      verbose_eval=0)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    end_time = datetime.datetime.fromtimestamp(time.time())\n",
    "    seconds = (end_time - start_time).total_seconds()\n",
    "    minutes = round(seconds/60, 1)\n",
    "    \n",
    "    res = auc(y_valid, y_pred)\n",
    "    print(i, \"ROC AUC:\", round(res, 4), \"F-score:\", \n",
    "          round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), \n",
    "          minutes, \"minutes\\n\")\n",
    "    \n",
    "    results.append((params, res))\n",
    "    for key in param_static:\n",
    "        del params[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "sorted_results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
