{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ParameterSampler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import fbeta_score, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.observer import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.util import load_logs\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "input_path = \"../input/\"\n",
    "output_path = \"../output/\"\n",
    "model_path = \"../models/\"\n",
    "\n",
    "ensure_dir(model_path)\n",
    "ensure_dir(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_path+'train.csv.zip')\n",
    "\n",
    "label = train_df.target\n",
    "train = train_df.drop(['ID_code','target'],axis=1)\n",
    "\n",
    "test = pd.read_csv(input_path+'test.csv.zip')\n",
    "test = test.drop(['ID_code'],axis=1)\n",
    "\n",
    "test_filtered = pd.read_pickle(input_path+'test_filtered.pkl')\n",
    "test_filtered = test_filtered.loc[:,train.columns]\n",
    "\n",
    "train_test = pd.concat([train,test_filtered]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d071498f5e48b399a01a14599321d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vcs_train = {}\n",
    "vcs_test = {}\n",
    "vcs_train_test = {}\n",
    "\n",
    "for col in tqdm(train.columns):\n",
    "    vcs_train_test[col] = train_test.loc[:,col].value_counts()/300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849c0ebd54204dd9a00a2de57eae1c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8cf9ea4bcd41febcbcb1a12765fdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def feature_generator(df):\n",
    "    for i in tqdm(range(200)):\n",
    "        col = \"var_\"+str(i)\n",
    "        vtraintest = vcs_train_test[col]\n",
    "        t = vtraintest[df[col]].fillna(0).values\n",
    "\n",
    "        df[col+'_train_test_sum_vcs'] = t\n",
    "        df[col+'_train_test_sum_vcs_prod'] = df[col]*t\n",
    "#         df[col+'_train_test_sum_vcs_sign'] = (df[col+\"_train_test_sum_vcs_prod\"]>0).astype(int)\n",
    "#         df[col+'_train_test_sum_vcs_div'] = df[col]/t\n",
    "#         df[col+'_train_test_sum_vcs_minus'] = scale(df[col]) - scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_plus'] = scale(df[col]) + scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_min'] = np.min(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_max'] = np.max(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_pow'] = np.power(abs(scale(df[col])), abs(scale(t)))\n",
    "#         df[col+'_train_test_sum_vcs_log'] = np.log(abs(scale(df[col])), abs(scale(t)))\n",
    "        \n",
    "feature_generator(train)\n",
    "feature_generator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train\n",
    "dt = test\n",
    "\n",
    "cols = sorted(list(set(df.columns)-{\"label\"}))\n",
    "print(len(cols))\n",
    "\n",
    "df[\"label\"] = label\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"clf\"] = 0\n",
    "dt[\"clf\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'clf_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 1\n",
    "        clf = LogisticRegression(C=c,\n",
    "                                 solver=\"newton-cg\",\n",
    "                                 penalty=\"l2\", \n",
    "                                 n_jobs=-1, \n",
    "                                 max_iter=1000).fit(X_train, y_train) \n",
    "        joblib.dump(clf, fname)\n",
    "    else:\n",
    "        clf = joblib.load(fname)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"clf\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"clf\"] += clf.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"clf\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"clf\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"clf\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"svc\"] = 0\n",
    "dt[\"svc\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'svc_'+str(i)+'.pkl'\n",
    "    #print(fname)\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 100\n",
    "        svc = SVC(C=c,\n",
    "                  probability=True).fit(X_train, y_train) \n",
    "        \n",
    "        joblib.dump(svc, fname)\n",
    "    else:\n",
    "        svc = joblib.load(fname)\n",
    "\n",
    "    y_pred = svc.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"svc\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"svc\"] += svc.predict(Z)/5\n",
    "\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"svc\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"svc\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"svc\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"nei\"] = 0\n",
    "dt[\"nei\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'nei_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        nei = KNeighborsClassifier(n_neighbors=50,\n",
    "                                   p=1, n_jobs=-1).fit(X_train, y_train) \n",
    "        joblib.dump(nei, fname)\n",
    "    else:\n",
    "        nei = joblib.load(fname)\n",
    "\n",
    "    y_pred = nei.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"nei\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"nei\"] += nei.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"nei\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"nei\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"nei\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 10000\n",
    "early_stop_rounds = 200\n",
    "\n",
    "params = {'lambda_l1': 0, \n",
    "          'lambda_l2': 10,\n",
    "          'feature_fraction':0.9,\n",
    "          'learning_rate': 0.03, \n",
    "          'max_depth': 4,\n",
    "          #'min_data_in_leaf':20,\n",
    "          #'num_leaves':2**5-1,\n",
    "          'boosting_type': 'gbrt', #dart gbrt\n",
    "          'objective': 'binary', \n",
    "          'metric': 'auc',\n",
    "          #'weight': [1, 0.5],\n",
    "          #'device': 'gpu',\n",
    "          #'gpu_platform_id': '0',\n",
    "          #'gpu_device_id': '0',\n",
    "          'max_bin': 1024,\n",
    "          'n_jobs':-1\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"lgb\"] = 0\n",
    "dt[\"lgb\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    fname = model_path+'lgb_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        model = lgb.train(params,\n",
    "                            d_train,\n",
    "                            num_boost_round=rounds,\n",
    "                            valid_sets=[d_train, d_valid],\n",
    "                            valid_names=['train','valid'],\n",
    "                            #feval=lgb_f1_score,\n",
    "                            early_stopping_rounds=early_stop_rounds,\n",
    "                            verbose_eval=100)\n",
    "        \n",
    "        joblib.dump(model, fname)\n",
    "    else:\n",
    "        model = joblib.load(fname)\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    df.loc[valid_index, \"lgb\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"lgb\"] += model.predict(Z)/5\n",
    "    break\n",
    "    \n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"lgb\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"lgb\"]>0.5, beta=1), 4))\n",
    "\n",
    "# [3992]\ttrain's auc: 0.989264\tvalid's auc: 0.913532\n",
    "# ROC AUC: 0.9135 \n",
    "# F-score: 0.5195 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1,2,5]\n",
    "\n",
    "df[\"avg\"] = (w[0]*df[\"clf\"]+w[1]*df[\"svc\"]+w[2]*df[\"lgb\"])/sum(w)\n",
    "dt[\"avg\"] = (w[0]*dt[\"clf\"]+w[1]*dt[\"svc\"]+w[2]*dt[\"lgb\"])/sum(w)\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"avg\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"avg\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dt[\"avg\"] > 0.5) / len(dt), np.sum(df[\"avg\"] > 0.5) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(dt[\"avg\"] > 0.5)\n",
    "np.mean(predictions[:2*len(predictions)//5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[[\"Image\",\"avg\"]].to_csv(\"test_prediction_top5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 300))\n",
    "lgb.plot_importance(model, max_num_features=len(cols), ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]>0.5)&(df.label!=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]<0.5)&(df.label==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "              'max_depth': [3,4,5],\n",
    "              'learning_rate': np.linspace(0.01, 0.1, 10),\n",
    "              'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "              'lambda_l1': np.linspace(1, 10, 10),\n",
    "              'lambda_l2': np.linspace(1, 10, 10)\n",
    "            }\n",
    "\n",
    "param_static = {\n",
    "                'boosting_type': 'gbrt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'max_bin': 1024,\n",
    "                'n_jobs': -1\n",
    "               }\n",
    "\n",
    "param_list = list(ParameterSampler(param_grid, \n",
    "                                   n_iter=10))\n",
    "\n",
    "rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
    "                for d in param_list]\n",
    "\n",
    "rounds = 10000\n",
    "early_stop_rounds = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'learning_rate': 0.04, 'lambda_l2': 4.0, 'lambda_l1': 2.0, 'feature_fraction': 0.9}\n",
      "0 ROC AUC: 0.9127 F-score: 0.5259 3.5 minutes\n",
      "\n",
      "{'max_depth': 4, 'learning_rate': 0.07, 'lambda_l2': 7.0, 'lambda_l1': 2.0, 'feature_fraction': 0.8}\n",
      "1 ROC AUC: 0.9114 F-score: 0.5259 1.8 minutes\n",
      "\n",
      "{'max_depth': 3, 'learning_rate': 0.09, 'lambda_l2': 7.0, 'lambda_l1': 1.0, 'feature_fraction': 0.7}\n",
      "2 ROC AUC: 0.9133 F-score: 0.5461 1.2 minutes\n",
      "\n",
      "{'max_depth': 3, 'learning_rate': 0.09, 'lambda_l2': 9.0, 'lambda_l1': 10.0, 'feature_fraction': 0.9}\n",
      "3 ROC AUC: 0.9133 F-score: 0.557 1.9 minutes\n",
      "\n",
      "{'max_depth': 4, 'learning_rate': 0.07, 'lambda_l2': 9.0, 'lambda_l1': 10.0, 'feature_fraction': 0.8}\n"
     ]
    }
   ],
   "source": [
    "for train_index, valid_index in skf.split(X, y):\n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    break\n",
    "\n",
    "results = []\n",
    "for i, params in enumerate(rounded_list):\n",
    "    print(params)\n",
    "    start_time = datetime.datetime.fromtimestamp(time.time())\n",
    "    \n",
    "    for key in param_static:\n",
    "        params[key] = param_static[key]\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      d_train,\n",
    "                      num_boost_round=rounds,\n",
    "                      valid_sets=[d_train, d_valid],\n",
    "                      valid_names=['train','valid'],\n",
    "                      #feval=lgb_f1_score,\n",
    "                      early_stopping_rounds=early_stop_rounds,\n",
    "                      verbose_eval=0)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    end_time = datetime.datetime.fromtimestamp(time.time())\n",
    "    seconds = (end_time - start_time).total_seconds()\n",
    "    minutes = round(seconds/60, 1)\n",
    "    \n",
    "    res = auc(y_valid, y_pred)\n",
    "    print(i, \"ROC AUC:\", round(res, 4), \"F-score:\", \n",
    "          round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), \n",
    "          minutes, \"minutes\\n\")\n",
    "    \n",
    "    results.append((params, res))\n",
    "    for key in param_static:\n",
    "        del params[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "sorted_results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
