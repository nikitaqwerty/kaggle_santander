{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import fbeta_score, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.observer import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.util import load_logs\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "input_path = \"../input/\"\n",
    "output_path = \"../output/\"\n",
    "model_path = \"../models/\"\n",
    "\n",
    "ensure_dir(model_path)\n",
    "ensure_dir(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_path+'train.csv.zip')\n",
    "\n",
    "label = train_df.target\n",
    "train = train_df.drop(['ID_code','target'],axis=1)\n",
    "\n",
    "test = pd.read_csv(input_path+'test.csv.zip')\n",
    "test = test.drop(['ID_code'],axis=1)\n",
    "\n",
    "test_filtered = pd.read_pickle(input_path+'test_filtered.pkl')\n",
    "test_filtered = test_filtered.loc[:,train.columns]\n",
    "\n",
    "train_test = pd.concat([train,test_filtered]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe7f89efe90444a871bf1d97f51b84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vcs_train = {}\n",
    "vcs_test = {}\n",
    "vcs_train_test = {}\n",
    "\n",
    "for col in tqdm(train.columns):\n",
    "    vcs_train_test[col] = train_test.loc[:,col].value_counts()/300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02201a59140c4fe1b75f32400500558b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da493900fa1482e88cc2945bf205c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def feature_generator(df):\n",
    "    for i in tqdm(range(200)):\n",
    "        col = \"var_\"+str(i)\n",
    "        vtraintest = vcs_train_test[col]\n",
    "        t = vtraintest[df[col]].fillna(0).values\n",
    "\n",
    "        df[col+'_train_test_sum_vcs'] = t\n",
    "        df[col+'_train_test_sum_vcs_prod'] = df[col]*t\n",
    "#         df[col+'_train_test_sum_vcs_sign'] = (df[col+\"_train_test_sum_vcs_prod\"]>0).astype(int)\n",
    "#         df[col+'_train_test_sum_vcs_div'] = df[col]/t\n",
    "#         df[col+'_train_test_sum_vcs_minus'] = scale(df[col]) - scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_plus'] = scale(df[col]) + scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_min'] = np.min(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_max'] = np.max(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_pow'] = np.power(abs(scale(df[col])), abs(scale(t)))\n",
    "#         df[col+'_train_test_sum_vcs_log'] = np.log(abs(scale(df[col])), abs(scale(t)))\n",
    "        \n",
    "feature_generator(train)\n",
    "feature_generator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "df = train\n",
    "dt = test\n",
    "\n",
    "cols = sorted(list(set(df.columns)-{\"label\"}))\n",
    "print(len(cols))\n",
    "\n",
    "df[\"label\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"clf\"] = 0\n",
    "dt[\"clf\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'clf_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 1\n",
    "        clf = LogisticRegression(C=c,\n",
    "                                 solver=\"newton-cg\",\n",
    "                                 penalty=\"l2\", \n",
    "                                 n_jobs=-1, \n",
    "                                 max_iter=1000).fit(X_train, y_train) \n",
    "        joblib.dump(clf, fname)\n",
    "    else:\n",
    "        clf = joblib.load(fname)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"clf\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"clf\"] += clf.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"clf\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"clf\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"clf\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"svc\"] = 0\n",
    "dt[\"svc\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'svc_'+str(i)+'.pkl'\n",
    "    #print(fname)\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 100\n",
    "        svc = SVC(C=c,\n",
    "                  probability=True).fit(X_train, y_train) \n",
    "        \n",
    "        joblib.dump(svc, fname)\n",
    "    else:\n",
    "        svc = joblib.load(fname)\n",
    "\n",
    "    y_pred = svc.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"svc\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"svc\"] += svc.predict(Z)/5\n",
    "\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"svc\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"svc\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"svc\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"nei\"] = 0\n",
    "dt[\"nei\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'nei_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        nei = KNeighborsClassifier(n_neighbors=50,\n",
    "                                   p=1, n_jobs=-1).fit(X_train, y_train) \n",
    "        joblib.dump(nei, fname)\n",
    "    else:\n",
    "        nei = joblib.load(fname)\n",
    "\n",
    "    y_pred = nei.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"nei\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"nei\"] += nei.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"nei\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"nei\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"nei\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 10000\n",
    "early_stop_rounds = 200\n",
    "\n",
    "params = {'lambda_l1': 0, \n",
    "          'lambda_l2': 10,\n",
    "          'feature_fraction':0.9,\n",
    "          'learning_rate': 0.03, \n",
    "          'max_depth': 4,\n",
    "          #'min_data_in_leaf':20,\n",
    "          #'num_leaves':2**5-1,\n",
    "          'boosting_type': 'gbrt', #dart gbrt\n",
    "          'objective': 'binary', \n",
    "          'metric': 'auc',\n",
    "          #'weight': [1, 0.5],\n",
    "          #'device': 'gpu',\n",
    "          #'gpu_platform_id': '0',\n",
    "          #'gpu_device_id': '0',\n",
    "          'max_bin': 1024,\n",
    "          'n_jobs':-1\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttrain's auc: 0.836572\tvalid's auc: 0.808477\n",
      "[200]\ttrain's auc: 0.876608\tvalid's auc: 0.844941\n",
      "[300]\ttrain's auc: 0.898476\tvalid's auc: 0.862659\n",
      "[400]\ttrain's auc: 0.912644\tvalid's auc: 0.874368\n",
      "[500]\ttrain's auc: 0.922846\tvalid's auc: 0.881846\n",
      "[600]\ttrain's auc: 0.930758\tvalid's auc: 0.887439\n",
      "[700]\ttrain's auc: 0.936658\tvalid's auc: 0.891257\n",
      "[800]\ttrain's auc: 0.941571\tvalid's auc: 0.894522\n",
      "[900]\ttrain's auc: 0.945676\tvalid's auc: 0.897096\n",
      "[1000]\ttrain's auc: 0.949255\tvalid's auc: 0.899294\n",
      "[1100]\ttrain's auc: 0.952249\tvalid's auc: 0.901108\n",
      "[1200]\ttrain's auc: 0.954903\tvalid's auc: 0.902687\n",
      "[1300]\ttrain's auc: 0.957296\tvalid's auc: 0.903811\n",
      "[1400]\ttrain's auc: 0.959548\tvalid's auc: 0.90502\n",
      "[1500]\ttrain's auc: 0.961488\tvalid's auc: 0.905927\n",
      "[1600]\ttrain's auc: 0.963235\tvalid's auc: 0.906565\n",
      "[1700]\ttrain's auc: 0.964867\tvalid's auc: 0.907214\n",
      "[1800]\ttrain's auc: 0.966461\tvalid's auc: 0.907862\n",
      "[1900]\ttrain's auc: 0.967905\tvalid's auc: 0.908419\n",
      "[2000]\ttrain's auc: 0.969247\tvalid's auc: 0.908932\n",
      "[2100]\ttrain's auc: 0.970519\tvalid's auc: 0.909396\n",
      "[2200]\ttrain's auc: 0.971691\tvalid's auc: 0.909852\n",
      "[2300]\ttrain's auc: 0.972785\tvalid's auc: 0.910178\n",
      "[2400]\ttrain's auc: 0.973861\tvalid's auc: 0.910508\n",
      "[2500]\ttrain's auc: 0.974888\tvalid's auc: 0.910698\n",
      "[2600]\ttrain's auc: 0.975845\tvalid's auc: 0.910983\n",
      "[2700]\ttrain's auc: 0.976763\tvalid's auc: 0.911179\n",
      "[2800]\ttrain's auc: 0.977612\tvalid's auc: 0.911385\n",
      "[2900]\ttrain's auc: 0.978436\tvalid's auc: 0.911481\n",
      "[3000]\ttrain's auc: 0.979204\tvalid's auc: 0.911592\n",
      "[3100]\ttrain's auc: 0.979979\tvalid's auc: 0.911697\n",
      "[3200]\ttrain's auc: 0.980741\tvalid's auc: 0.911738\n",
      "[3300]\ttrain's auc: 0.981461\tvalid's auc: 0.911795\n",
      "[3400]\ttrain's auc: 0.982122\tvalid's auc: 0.911871\n",
      "[3500]\ttrain's auc: 0.98275\tvalid's auc: 0.911988\n",
      "[3600]\ttrain's auc: 0.983389\tvalid's auc: 0.912093\n",
      "[3700]\ttrain's auc: 0.984029\tvalid's auc: 0.912192\n",
      "[3800]\ttrain's auc: 0.984625\tvalid's auc: 0.912254\n",
      "[3900]\ttrain's auc: 0.985193\tvalid's auc: 0.912344\n",
      "[4000]\ttrain's auc: 0.985758\tvalid's auc: 0.91238\n",
      "[4100]\ttrain's auc: 0.986267\tvalid's auc: 0.912397\n",
      "[4200]\ttrain's auc: 0.986785\tvalid's auc: 0.912463\n",
      "[4300]\ttrain's auc: 0.987296\tvalid's auc: 0.912449\n",
      "[4400]\ttrain's auc: 0.987783\tvalid's auc: 0.912458\n",
      "[4500]\ttrain's auc: 0.988242\tvalid's auc: 0.912552\n",
      "[4600]\ttrain's auc: 0.988682\tvalid's auc: 0.9126\n",
      "[4700]\ttrain's auc: 0.989138\tvalid's auc: 0.912545\n",
      "[4800]\ttrain's auc: 0.989548\tvalid's auc: 0.912563\n",
      "Early stopping, best iteration is:\n",
      "[4609]\ttrain's auc: 0.98873\tvalid's auc: 0.912611\n",
      "ROC AUC: 0.9126 \n",
      "F-score: 0.524 0\n",
      "\n",
      "ROC AUC: 0.5165 \n",
      "F-score: 0.1407\n",
      "CPU times: user 2h 16min 41s, sys: 25.4 s, total: 2h 17min 7s\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df[\"lgb\"] = 0\n",
    "dt[\"lgb\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    fname = model_path+'lgb_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        model = lgb.train(params,\n",
    "                            d_train,\n",
    "                            num_boost_round=rounds,\n",
    "                            valid_sets=[d_train, d_valid],\n",
    "                            valid_names=['train','valid'],\n",
    "                            #feval=lgb_f1_score,\n",
    "                            early_stopping_rounds=early_stop_rounds,\n",
    "                            verbose_eval=100)\n",
    "        \n",
    "        joblib.dump(model, fname)\n",
    "    else:\n",
    "        model = joblib.load(fname)\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    df.loc[valid_index, \"lgb\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"lgb\"] += model.predict(Z)/5\n",
    "    break\n",
    "    \n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"lgb\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"lgb\"]>0.5, beta=1), 4))\n",
    "\n",
    "# [3992]\ttrain's auc: 0.989264\tvalid's auc: 0.913532\n",
    "# ROC AUC: 0.9135 \n",
    "# F-score: 0.5195 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1,2,5]\n",
    "\n",
    "df[\"avg\"] = (w[0]*df[\"clf\"]+w[1]*df[\"svc\"]+w[2]*df[\"lgb\"])/sum(w)\n",
    "dt[\"avg\"] = (w[0]*dt[\"clf\"]+w[1]*dt[\"svc\"]+w[2]*dt[\"lgb\"])/sum(w)\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"avg\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"avg\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dt[\"avg\"] > 0.5) / len(dt), np.sum(df[\"avg\"] > 0.5) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(dt[\"avg\"] > 0.5)\n",
    "np.mean(predictions[:2*len(predictions)//5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[[\"Image\",\"avg\"]].to_csv(\"test_prediction_top5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Light GBM Feature Importance')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 300))\n",
    "lgb.plot_importance(model, max_num_features=len(cols), ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]>0.5)&(df.label!=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]<0.5)&(df.label==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
