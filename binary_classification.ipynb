{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ParameterSampler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import fbeta_score, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.observer import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.util import load_logs\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "input_path = \"../input/\"\n",
    "output_path = \"../output/\"\n",
    "model_path = \"../models/\"\n",
    "\n",
    "ensure_dir(model_path)\n",
    "ensure_dir(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_path+'train.csv.zip')\n",
    "\n",
    "label = train_df.target\n",
    "train = train_df.drop(['ID_code','target'],axis=1)\n",
    "\n",
    "test = pd.read_csv(input_path+'test.csv.zip')\n",
    "test = test.drop(['ID_code'],axis=1)\n",
    "\n",
    "test_filtered = pd.read_pickle(input_path+'test_filtered.pkl')\n",
    "test_filtered = test_filtered.loc[:,train.columns]\n",
    "\n",
    "train_test = pd.concat([train,test_filtered]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d071498f5e48b399a01a14599321d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vcs_train = {}\n",
    "vcs_test = {}\n",
    "vcs_train_test = {}\n",
    "\n",
    "for col in tqdm(train.columns):\n",
    "    vcs_train_test[col] = train_test.loc[:,col].value_counts()/300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849c0ebd54204dd9a00a2de57eae1c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8cf9ea4bcd41febcbcb1a12765fdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def feature_generator(df):\n",
    "    for i in tqdm(range(200)):\n",
    "        col = \"var_\"+str(i)\n",
    "        vtraintest = vcs_train_test[col]\n",
    "        t = vtraintest[df[col]].fillna(0).values\n",
    "\n",
    "        df[col+'_train_test_sum_vcs'] = t\n",
    "        df[col+'_train_test_sum_vcs_prod'] = df[col]*t\n",
    "#         df[col+'_train_test_sum_vcs_sign'] = (df[col+\"_train_test_sum_vcs_prod\"]>0).astype(int)\n",
    "#         df[col+'_train_test_sum_vcs_div'] = df[col]/t\n",
    "#         df[col+'_train_test_sum_vcs_minus'] = scale(df[col]) - scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_plus'] = scale(df[col]) + scale(t)\n",
    "#         df[col+'_train_test_sum_vcs_min'] = np.min(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_max'] = np.max(scale(df[col]), scale(t))\n",
    "#         df[col+'_train_test_sum_vcs_pow'] = np.power(abs(scale(df[col])), abs(scale(t)))\n",
    "#         df[col+'_train_test_sum_vcs_log'] = np.log(abs(scale(df[col])), abs(scale(t)))\n",
    "        \n",
    "feature_generator(train)\n",
    "feature_generator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train\n",
    "dt = test\n",
    "\n",
    "cols = sorted(list(set(df.columns)-{\"label\"}))\n",
    "print(len(cols))\n",
    "\n",
    "df[\"label\"] = label\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"clf\"] = 0\n",
    "dt[\"clf\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'clf_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 1\n",
    "        clf = LogisticRegression(C=c,\n",
    "                                 solver=\"newton-cg\",\n",
    "                                 penalty=\"l2\", \n",
    "                                 n_jobs=-1, \n",
    "                                 max_iter=1000).fit(X_train, y_train) \n",
    "        joblib.dump(clf, fname)\n",
    "    else:\n",
    "        clf = joblib.load(fname)\n",
    "\n",
    "    y_pred = clf.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"clf\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"clf\"] += clf.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"clf\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"clf\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"clf\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"svc\"] = 0\n",
    "dt[\"svc\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'svc_'+str(i)+'.pkl'\n",
    "    #print(fname)\n",
    "    if DEV or not isfile(fname):\n",
    "        c = 100\n",
    "        svc = SVC(C=c,\n",
    "                  probability=True).fit(X_train, y_train) \n",
    "        \n",
    "        joblib.dump(svc, fname)\n",
    "    else:\n",
    "        svc = joblib.load(fname)\n",
    "\n",
    "    y_pred = svc.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"svc\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"svc\"] += svc.predict(Z)/5\n",
    "\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"svc\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"svc\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"svc\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"nei\"] = 0\n",
    "dt[\"nei\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "    \n",
    "    fname = model_path+'nei_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        nei = KNeighborsClassifier(n_neighbors=50,\n",
    "                                   p=1, n_jobs=-1).fit(X_train, y_train) \n",
    "        joblib.dump(nei, fname)\n",
    "    else:\n",
    "        nei = joblib.load(fname)\n",
    "\n",
    "    y_pred = nei.predict_proba(X_valid)[:,1] \n",
    "    df.loc[valid_index, \"nei\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"nei\"] += nei.predict(Z)/5\n",
    "    \n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"nei\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"nei\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols+=[\"nei\"]\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 10000\n",
    "early_stop_rounds = 200\n",
    "\n",
    "params = {'lambda_l1': 0, \n",
    "          'lambda_l2': 10,\n",
    "          'feature_fraction':0.9,\n",
    "          'learning_rate': 0.03, \n",
    "          'max_depth': 4,\n",
    "          #'min_data_in_leaf':20,\n",
    "          #'num_leaves':2**5-1,\n",
    "          'boosting_type': 'gbrt', #dart gbrt\n",
    "          'objective': 'binary', \n",
    "          'metric': 'auc',\n",
    "          #'weight': [1, 0.5],\n",
    "          #'device': 'gpu',\n",
    "          #'gpu_platform_id': '0',\n",
    "          #'gpu_device_id': '0',\n",
    "          'max_bin': 1024,\n",
    "          'n_jobs':-1\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"lgb\"] = 0\n",
    "dt[\"lgb\"] = 0\n",
    "\n",
    "i = -1\n",
    "for train_index, valid_index in skf.split(X, y):\n",
    "    i+=1\n",
    "        \n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    fname = model_path+'lgb_'+str(i)+'.pkl'\n",
    "    if DEV or not isfile(fname):\n",
    "        model = lgb.train(params,\n",
    "                            d_train,\n",
    "                            num_boost_round=rounds,\n",
    "                            valid_sets=[d_train, d_valid],\n",
    "                            valid_names=['train','valid'],\n",
    "                            #feval=lgb_f1_score,\n",
    "                            early_stopping_rounds=early_stop_rounds,\n",
    "                            verbose_eval=100)\n",
    "        \n",
    "        joblib.dump(model, fname)\n",
    "    else:\n",
    "        model = joblib.load(fname)\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_valid)\n",
    "    df.loc[valid_index, \"lgb\"] = y_pred\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)\n",
    "    \n",
    "    dt[\"lgb\"] += model.predict(Z)/5\n",
    "    break\n",
    "    \n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"lgb\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"lgb\"]>0.5, beta=1), 4))\n",
    "\n",
    "# [3992]\ttrain's auc: 0.989264\tvalid's auc: 0.913532\n",
    "# ROC AUC: 0.9135 \n",
    "# F-score: 0.5195 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1,2,5]\n",
    "\n",
    "df[\"avg\"] = (w[0]*df[\"clf\"]+w[1]*df[\"svc\"]+w[2]*df[\"lgb\"])/sum(w)\n",
    "dt[\"avg\"] = (w[0]*dt[\"clf\"]+w[1]*dt[\"svc\"]+w[2]*dt[\"lgb\"])/sum(w)\n",
    "\n",
    "print(\"\\nROC AUC:\", round(auc(df.label, df[\"avg\"]), 4), \n",
    "      \"\\nF-score:\", round(fbeta_score(df.label, df[\"avg\"]>0.5, beta=1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dt[\"avg\"] > 0.5) / len(dt), np.sum(df[\"avg\"] > 0.5) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(dt[\"avg\"] > 0.5)\n",
    "np.mean(predictions[:2*len(predictions)//5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[[\"Image\",\"avg\"]].to_csv(\"test_prediction_top5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 300))\n",
    "lgb.plot_importance(model, max_num_features=len(cols), ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]>0.5)&(df.label!=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df[\"lgb\"]<0.5)&(df.label==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #MinMaxScaler StandardScaler RobustScaler\n",
    "\n",
    "X = scaler.fit_transform(df[cols])\n",
    "Z = scaler.transform(dt[cols])\n",
    "y = list(df.label)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "              'max_depth': [3,4,5],\n",
    "              'learning_rate': np.linspace(0.01, 0.1, 10),\n",
    "              'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "              'lambda_l1': np.linspace(1, 10, 10),\n",
    "              'lambda_l2': np.linspace(1, 10, 10)\n",
    "            }\n",
    "\n",
    "param_list = list(ParameterSampler(param_grid, \n",
    "                                   n_iter=10))\n",
    "\n",
    "rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
    "                for d in param_list]\n",
    "\n",
    "rounds = 10000\n",
    "early_stop_rounds = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'max_depth': 5, 'learning_rate': 0.04, 'lambda_l2': 7.0, 'lambda_l1': 8.0, 'feature_fraction': 0.6}\n",
      "ROC AUC: 0.9125 \tF-score: 0.5219 0\n",
      "1 {'max_depth': 5, 'learning_rate': 0.08, 'lambda_l2': 6.0, 'lambda_l1': 2.0, 'feature_fraction': 0.6}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-870f72e304b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0;31m#feval=lgb_f1_score,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                         verbose_eval=0)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1758\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1760\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1761\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_index, valid_index in skf.split(X, y):\n",
    "    X_train = X[train_index, :]\n",
    "    X_valid = X[valid_index, :]\n",
    "\n",
    "    y_train = df.loc[train_index, \"label\"]\n",
    "    y_valid = df.loc[valid_index, \"label\"]\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, y_train, feature_name=cols)\n",
    "    d_valid = lgb.Dataset(X_valid, y_valid, feature_name=cols)    \n",
    "    \n",
    "    break\n",
    "\n",
    "for i, params in enumerate(rounded_list):\n",
    "    print(i, params)\n",
    "    \n",
    "    params['boosting_type'] = 'gbrt'\n",
    "    params['objective'] = 'binary'\n",
    "    params['metric'] = 'auc'\n",
    "    params['max_bin'] = 1024\n",
    "    params['n_jobs'] = -1\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                        d_train,\n",
    "                        num_boost_round=rounds,\n",
    "                        valid_sets=[d_train, d_valid],\n",
    "                        valid_names=['train','valid'],\n",
    "                        #feval=lgb_f1_score,\n",
    "                        early_stopping_rounds=early_stop_rounds,\n",
    "                        verbose_eval=0)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    print(\"ROC AUC:\", round(auc(y_valid, y_pred), 4), \n",
    "          \"\\tF-score:\", round(fbeta_score(y_valid, y_pred>0.5, beta=1), 4), i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
