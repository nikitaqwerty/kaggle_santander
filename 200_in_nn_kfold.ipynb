{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.nn.modules.loss import BCEWithLogitsLoss, BCELoss\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df.target\n",
    "\n",
    "train = train_df.drop(['ID_code','target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filtered = pd.read_pickle('test_filtred.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filtered = test_filtered.loc[:,train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['ID_code'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train,test_filtered]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4d0ba963fb4bb9852e38f0d0430a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vcs_train_test = {}\n",
    "\n",
    "\n",
    "for col in tqdm(train.columns):\n",
    "\n",
    "    vcs_train_test[col] = train_test.loc[:,col].value_counts()/300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfe1d0738cd47ef97f550d2531d013b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(train.columns):\n",
    "\n",
    "    vtraintest = vcs_train_test[col]\n",
    "    \n",
    "    t = vtraintest[train[col]].fillna(0).values\n",
    "    train[col+'_train_test_sum_vcs'] = t\n",
    "    \n",
    "    train[col+'_train_test_sum_vcs_product'] = train[col]*t\n",
    "\n",
    "    t = vtraintest[test[col]].fillna(0).values\n",
    "    test[col+'_train_test_sum_vcs'] = t\n",
    "    \n",
    "    test[col+'_train_test_sum_vcs_product'] = test[col]*t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(scaler.fit_transform(train),columns=cols)\n",
    "test = pd.DataFrame(scaler.transform(test),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    random_seed = 42\n",
    "\n",
    "\n",
    "    def __init__(self, D_in=3, features = 200):\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        \n",
    "        super(NN, self).__init__()\n",
    "        self.layer = []\n",
    "        layer_size = D_in\n",
    "        enc_out = 30\n",
    "        for i in range(features):\n",
    "            \n",
    "            layer = torch.nn.Sequential(torch.nn.Linear(layer_size, enc_out//2),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(enc_out//2, enc_out),\n",
    "                                       torch.nn.ReLU())\n",
    "            setattr(self, 'layer_' + str(i), layer)\n",
    "        \n",
    "\n",
    "        self.linear3 = torch.nn.Linear(features*enc_out,1)        \n",
    "\n",
    "    def forward(self, y):\n",
    "        res = []\n",
    "        for i in range(200):\n",
    "            layer = getattr(self, 'layer_' + str(i))\n",
    "            res.append(layer(y[:,i,:]) )\n",
    "        y = torch.cat(res,1)\n",
    "        y = self.linear3(y)\n",
    "        return y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "loss_f = BCEWithLogitsLoss()\n",
    "\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cd812c54674f4e9aa1f1b5c4e3d6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "LOSS:  0.24902473\n",
      "AUC:  0.8360336045240018\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "random_seed = 42\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=False, random_state=99999)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values, label.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "    \n",
    "    train_tensors = []\n",
    "    val_tensors = []\n",
    "    test_tensors = []\n",
    "\n",
    "    for fff in range(200):\n",
    "        train_t = X_train.loc[trn_idx,[f'var_{fff}',f'var_{fff}_train_test_sum_vcs',\n",
    "                                       f'var_{fff}_train_test_sum_vcs_product']].values\n",
    "        val_t = X_train.loc[val_idx,[f'var_{fff}',f'var_{fff}_train_test_sum_vcs',\n",
    "                                     f'var_{fff}_train_test_sum_vcs_product']].values\n",
    "        test_t =  test[[f'var_{fff}',f'var_{fff}_train_test_sum_vcs',f'var_{fff}_train_test_sum_vcs_product']].values\n",
    "        train_tensors.append(torch.tensor(train_t, requires_grad=False, device=device, dtype=torch.float32))\n",
    "        val_tensors.append(torch.tensor(val_t, requires_grad=False, device=device, dtype=torch.float32))\n",
    "\n",
    "        test_tensors.append(torch.tensor(test_t, requires_grad=False, device=device, dtype=torch.float32))\n",
    "    \n",
    "    train_tensors = torch.cat(train_tensors,1).view((-1,200,3))\n",
    "    val_tensors = torch.cat(val_tensors,1).view((-1,200,3))\n",
    "    test_tensors = torch.cat(test_tensors,1).view((-1,200,3))\n",
    "    \n",
    "    y_train_t = torch.tensor(label[trn_idx].values, requires_grad=False, device=device, dtype=torch.float32)\n",
    "    y_val_t = torch.tensor(label[val_idx].values, requires_grad=False, device=device, dtype=torch.float32)\n",
    "    \n",
    "    dataset = TensorDataset(train_tensors,y_train_t)\n",
    "    nn = NN().to(device)\n",
    "    optimizer = Adam(params=nn.parameters(), lr = 0.005)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[15, 25, 35, 55], gamma=0.5)\n",
    "    best_AUC = 0\n",
    "    early_stop = 0\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(100)):\n",
    "        dl = DataLoader(dataset, batch_size=batch_size, shuffle=True,num_workers=0)\n",
    "        for data,label_t in dl:\n",
    "            pred = nn(data)\n",
    "            loss = loss_f(pred, torch.unsqueeze(label_t,-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            val_pred = nn(val_tensors)\n",
    "            AUC = roc_auc_score(label[val_idx].values,val_pred.detach().cpu().numpy())\n",
    "            print('EPOCH {}'.format(epoch))\n",
    "            print('LOSS: ',loss_f(val_pred, torch.unsqueeze(y_val_t,-1)).detach().cpu().numpy())\n",
    "            print('AUC: ',AUC)\n",
    "            print('='*50)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if AUC > best_AUC:\n",
    "                early_stop = 0\n",
    "                best_AUC = AUC\n",
    "                torch.save(nn, 'best_auc_nn.pkl')\n",
    "            else:\n",
    "                print('SCORE IS NOT THE BEST. Early stop counter: {}'.format(early_stop))\n",
    "                early_stop += 1\n",
    "            \n",
    "            if early_stop == 15:\n",
    "                print('EARLY_STOPPING')\n",
    "                best_model = torch.load('best_auc_nn.pkl')\n",
    "                break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        oof[val_idx] = best_model(val_tensors).data.cpu().numpy().flatten()\n",
    "        \n",
    "        batch_size = 20000\n",
    "        blobs = []\n",
    "\n",
    "        for batch in torch.split(test_tensors,batch_size):\n",
    "            blob = best_model(batch).data.cpu().numpy().flatten()\n",
    "            blobs.append(blob)\n",
    "    predictions_test = np.concatenate(blobs)\n",
    "    \n",
    "    predictions += predictions_test / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(label, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.91843 \n"
     ]
    }
   ],
   "source": [
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(label, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.20609248, -0.82340122, -1.79933187, ..., -5.8816942 ,\n",
       "       -1.69825268, -4.62188035])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_sub['target'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_sub.to_csv('200in_nn_kfold.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
